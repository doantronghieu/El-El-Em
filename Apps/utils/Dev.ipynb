{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Sequence\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "import add_packages\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_feedback import streamlit_feedback\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "from my_langchain import (\n",
    "  chat_models, agent_tools, prompts, agents, smiths, runnables\n",
    ")\n",
    "\n",
    "from my_streamlit import utils\n",
    "from my_streamlit.utils import CHAT_ROLE, MSG_ITEM\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "st.set_page_config(\n",
    "  layout=\"wide\",\n",
    ")\n",
    "\n",
    "STATES = {\n",
    "  \"MESSAGES\": {\n",
    "    \"INITIAL_VALUE\": [],\n",
    "  },\n",
    "  \"CONTAINER_PLACEHOLDER\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"LAST_RUN\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"PROMPT_EXAMPLE\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"SELECTED_CHAT\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"BTN_NEW_CHAT\": {\n",
    "    \"INITIAL_VALUE\": \"widget\",\n",
    "  },\n",
    "  \"BTN_CLEAR_CHAT_HISTORY\": {\n",
    "    \"INITIAL_VALUE\": \"widget\",\n",
    "  },\n",
    "  \"BTN_CLEAR_CHAT\": {\n",
    "    \"INITIAL_VALUE\": \"widget\",\n",
    "  },\n",
    "}\n",
    "\n",
    "utils.initialize_session_state(STATES)\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "PROJECT_LS = \"default\" # LangSmith\n",
    "ENDPOINT_LC = \"https://api.smith.langchain.com\" # LangChain\n",
    "CLIENT_LC = smiths.Client(\n",
    "  api_url=ENDPOINT_LC, api_key=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    ")\n",
    "TRACER_LS = smiths.LangChainTracer(project_name=PROJECT_LS, client=CLIENT_LC)\n",
    "RUN_COLLECTOR = smiths.RunCollectorCallbackHandler()\n",
    "\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def get_LC_run_url(run_id):\n",
    "  try:\n",
    "    result = CLIENT_LC.read_run(run_id).url\n",
    "  except:\n",
    "    result = None\n",
    "    \n",
    "  return result\n",
    "\n",
    "@st.cache_resource\n",
    "def create_agent(\n",
    "  _llm: BaseLanguageModel, \n",
    "  _tools: Sequence[BaseTool], \n",
    "  _prompt: ChatPromptTemplate,\n",
    "  _agent_type: str,\n",
    ") -> Runnable:\n",
    "  agent = agents.MyAgent(\n",
    "    llm=_llm, tools=_tools, prompt=_prompt, agent_type=_agent_type\n",
    "  )\n",
    "  return agent\n",
    "\n",
    "def create_callbacks() -> list:\n",
    "  st_callback = utils.StreamlitCallbackHandler(st.container())\n",
    "  callbacks = [st_callback, TRACER_LS, RUN_COLLECTOR]\n",
    "  return callbacks\n",
    "\n",
    "def generate_response(\n",
    "  input: str, \n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  response = llm.invoke_agent(\n",
    "    input_message=input, \n",
    "    callbacks=create_callbacks()\n",
    "  )\n",
    "  \n",
    "  st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]] = RUN_COLLECTOR.traced_runs[0].id\n",
    "  \n",
    "  return response\n",
    "\n",
    "def render_last_msg_opt_btns():\n",
    "    if llm.chat_history:\n",
    "        # Create a new container and store its placeholder\n",
    "        st.session_state.container_placeholder = st.empty()\n",
    "        \n",
    "        with st.session_state.container_placeholder:\n",
    "            cols_last_msg_opts = st.columns([0.94, 0.03, 0.03])\n",
    "            cols_last_msg_opts[1].button(\"‚Üª\", key=\"btn_lst_msg_regenerate\")\n",
    "            cols_last_msg_opts[2].button(\"üìã\", key=\"btn_lst_msg_copy\")\n",
    "\n",
    "def process_on_user_input(\n",
    "  prompt: str, \n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  # Clear the container before displaying user's message\n",
    "  if st.session_state.container_placeholder is not None:\n",
    "      st.session_state.container_placeholder.empty()\n",
    "  \n",
    "  st.chat_message(CHAT_ROLE.user).markdown(prompt)\n",
    "  stream = generate_response(prompt, llm)\n",
    "  st.chat_message(CHAT_ROLE.assistant).write(stream)\n",
    "  \n",
    "  render_last_msg_opt_btns()\n",
    "  \n",
    "def render_chat_messages_on_rerun(\n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  for msg in llm.chat_history:\n",
    "    msg: Union[prompts.AIMessage, prompts.HumanMessage]\n",
    "    st.chat_message(msg.type).markdown(msg.content)\n",
    "\n",
    "def on_click_btn_clear_chat_history(\n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  llm. clear_chat_history()\n",
    "  del st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]]\n",
    "  st.toast(\":orange[History cleared]\", icon=\"üóëÔ∏è\")\n",
    "\n",
    "def on_click_btn_new_chat(\n",
    "  \n",
    "):\n",
    "  st.toast(\":green[Chat created]\", icon=\"‚úÖ\")\n",
    "\n",
    "\n",
    "def on_click_btn_clear_chat(\n",
    "  \n",
    "):\n",
    "  st.toast(\":red[Chat cleared]\", icon=\"‚ùå\")\n",
    "\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "llm = chat_models.chat_openai\n",
    "\n",
    "tool_search = agent_tools.TavilySearchResults(max_results=3)\n",
    "tools = [\n",
    "  tool_search,\n",
    "]\n",
    "\n",
    "prompt = prompts.create_prompt_tool_calling_agent()\n",
    "\n",
    "llm: agents.MyAgent = create_agent(\n",
    "  _llm=llm, \n",
    "  _tools=tools, \n",
    "  _prompt=prompt, \n",
    "  _agent_type=\"tool_calling\"\n",
    ")\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "containter_empty_btn_opts_holder = st.empty()\n",
    "\n",
    "\n",
    "render_chat_messages_on_rerun(llm=llm)\n",
    "\n",
    "with st.sidebar:\n",
    "  btn_new_chat = st.button(\n",
    "    label=\"üí¨\", \n",
    "    key=STATES[\"BTN_NEW_CHAT\"][\"KEY\"],\n",
    "    help=\"Create new Chat\",\n",
    "    on_click=on_click_btn_new_chat, \n",
    "    kwargs=dict()\n",
    "  )\n",
    "  \n",
    "  selected_chat = st.selectbox(\n",
    "    label=\"Chat\",\n",
    "    label_visibility=\"collapsed\",\n",
    "    help=\"Select Your Chat\",\n",
    "    placeholder=\"Chats\",\n",
    "    options=[\n",
    "      None,\n",
    "      \"Dummy Chat 1\",\n",
    "      \"Dummy Chat 2\",\n",
    "    ],\n",
    "    key=STATES[\"SELECTED_CHAT\"][\"KEY\"],\n",
    "  )\n",
    "  \n",
    "  prompt_example = st.selectbox(\n",
    "    label=\"Examples\",\n",
    "    label_visibility=\"collapsed\",\n",
    "    help=\"Example prompts\",\n",
    "    placeholder=\"Examples\",\n",
    "    options=[\n",
    "      None,\n",
    "      \"Hello\",\n",
    "      \"My name is Bob\",\n",
    "      \"What is my name?\",\n",
    "      \"Tell me a super long story about a dog\",\n",
    "      \"What is the question I just asked you?\",\n",
    "    ],\n",
    "    key=STATES[\"PROMPT_EXAMPLE\"][\"KEY\"],\n",
    "  )  \n",
    "  \n",
    "  #*----------------------------------------------------------------------------\n",
    "  \n",
    "  cols_clear = st.columns([0.25, 0.25, 0.5])\n",
    "  \n",
    "  btn_clear_chat_history = cols_clear[0].button(\n",
    "    label=\"üóëÔ∏è\", \n",
    "    help=\"Clear Chat History\",\n",
    "    key=STATES[\"BTN_CLEAR_CHAT_HISTORY\"][\"KEY\"],\n",
    "    on_click=on_click_btn_clear_chat_history, \n",
    "    kwargs=dict(llm=llm)\n",
    "  )\n",
    "  \n",
    "  btn_clear_chat = cols_clear[1].button(\n",
    "    label=\"‚ùå\", \n",
    "    help=\"Clear Chat\",\n",
    "    key=STATES[\"BTN_CLEAR_CHAT\"][\"KEY\"],\n",
    "    on_click=on_click_btn_clear_chat, \n",
    "    kwargs=dict()\n",
    "  )\n",
    "  \n",
    "#*----------------------------------------------------------------------------\n",
    "\n",
    "prompt: Union[str, None]\n",
    "prompt = st.chat_input(\"Say something\")\n",
    "\n",
    "if prompt_example:\n",
    "  prompt = prompt_example\n",
    "  del st.session_state[STATES[\"PROMPT_EXAMPLE\"][\"KEY\"]]\n",
    "  \n",
    "if prompt:\n",
    "  process_on_user_input(prompt=prompt, llm=llm)\n",
    "\n",
    "#*------------------------------------------------------------------------------\n",
    "# Feedback\n",
    "\n",
    "if st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]]:\n",
    "  run_url = get_LC_run_url(st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]])\n",
    "  \n",
    "  if run_url is None:\n",
    "    pass\n",
    "  \n",
    "  feedback = streamlit_feedback(\n",
    "    feedback_type=\"faces\",\n",
    "    optional_text_label=\"[Optional] Please provide an explanation\",\n",
    "    key=f'feedback_{st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]]}'\n",
    "  )\n",
    "  \n",
    "  if feedback:\n",
    "    scores = {\"üòÄ\": 1, \"üôÇ\": 0.75, \"üòê\": 0.5, \"üôÅ\": 0.25, \"üòû\": 0}\n",
    "    \n",
    "    CLIENT_LC.create_feedback(\n",
    "      st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]],\n",
    "      feedback[\"type\"],\n",
    "      score=scores[feedback[\"score\"]],\n",
    "      comment=feedback.get(\"text\", None)\n",
    "    )\n",
    "    \n",
    "    st.toast(\"Feedback recorded.\", icon=\"üìù\")\n",
    "\n",
    "# st.write(st.session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm.chat_history:\n",
    "\tcols_last_msg_opts = st.columns([0.92, 0.04, 0.04])\n",
    "\tcols_last_msg_opts[-2].button(\"‚Üª\")\n",
    "\tcols_last_msg_opts[-1].button(\"üìã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Sequence\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "import add_packages\n",
    "\n",
    "import streamlit as st\n",
    "from streamlit_feedback import streamlit_feedback\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "from my_langchain import (\n",
    "  chat_models, agent_tools, prompts, agents, smiths, runnables\n",
    ")\n",
    "\n",
    "from my_streamlit import utils\n",
    "from my_streamlit.utils import CHAT_ROLE, MSG_ITEM\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "st.set_page_config(\n",
    "  layout=\"wide\",\n",
    ")\n",
    "\n",
    "STATES = {\n",
    "  \"MESSAGES\": {\n",
    "    \"INITIAL_VALUE\": [],\n",
    "  },\n",
    "  \"CONTAINER_PLACEHOLDER\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"LAST_RUN\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"PROMPT_EXAMPLE\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"SELECTED_CHAT\": {\n",
    "    \"INITIAL_VALUE\": None,\n",
    "  },\n",
    "  \"BTN_NEW_CHAT\": {\n",
    "    \"INITIAL_VALUE\": \"widget\",\n",
    "  },\n",
    "  \"BTN_CLEAR_CHAT_HISTORY\": {\n",
    "    \"INITIAL_VALUE\": \"widget\",\n",
    "  },\n",
    "  \"BTN_CLEAR_CHAT\": {\n",
    "    \"INITIAL_VALUE\": \"widget\",\n",
    "  },\n",
    "}\n",
    "\n",
    "utils.initialize_session_state(STATES)\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "PROJECT_LS = \"default\" # LangSmith\n",
    "ENDPOINT_LC = \"https://api.smith.langchain.com\" # LangChain\n",
    "CLIENT_LC = smiths.Client(\n",
    "  api_url=ENDPOINT_LC, api_key=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    ")\n",
    "TRACER_LS = smiths.LangChainTracer(project_name=PROJECT_LS, client=CLIENT_LC)\n",
    "RUN_COLLECTOR = smiths.RunCollectorCallbackHandler()\n",
    "\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def get_LC_run_url(run_id):\n",
    "  try:\n",
    "    result = CLIENT_LC.read_run(run_id).url\n",
    "  except:\n",
    "    result = None\n",
    "    \n",
    "  return result\n",
    "\n",
    "@st.cache_resource\n",
    "def create_agent(\n",
    "  _llm: BaseLanguageModel, \n",
    "  _tools: Sequence[BaseTool], \n",
    "  _prompt: ChatPromptTemplate,\n",
    "  _agent_type: str,\n",
    ") -> Runnable:\n",
    "  agent = agents.MyAgent(\n",
    "    llm=_llm, tools=_tools, prompt=_prompt, agent_type=_agent_type\n",
    "  )\n",
    "  return agent\n",
    "\n",
    "def create_callbacks() -> list:\n",
    "  st_callback = utils.StreamlitCallbackHandler(st.container())\n",
    "  callbacks = [st_callback, TRACER_LS, RUN_COLLECTOR]\n",
    "  return callbacks\n",
    "\n",
    "def generate_response(\n",
    "  input: str, \n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  response = llm.invoke_agent(\n",
    "    input_message=input, \n",
    "    callbacks=create_callbacks()\n",
    "  )\n",
    "  \n",
    "  st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]] = RUN_COLLECTOR.traced_runs[0].id\n",
    "  \n",
    "  return response\n",
    "\n",
    "def render_last_msg_opt_btns():\n",
    "    if llm.chat_history:\n",
    "        # Create a new container and store its placeholder\n",
    "        st.session_state.container_placeholder = st.empty()\n",
    "        \n",
    "        with st.session_state.container_placeholder:\n",
    "            cols_last_msg_opts = st.columns([0.94, 0.03, 0.03])\n",
    "            cols_last_msg_opts[1].button(\"‚Üª\", key=\"btn_lst_msg_regenerate\")\n",
    "            cols_last_msg_opts[2].button(\"üìã\", key=\"btn_lst_msg_copy\")\n",
    "\n",
    "def process_on_user_input(\n",
    "  prompt: str, \n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  # Clear the container before displaying user's message\n",
    "  if st.session_state.container_placeholder is not None:\n",
    "      st.session_state.container_placeholder.empty()\n",
    "  \n",
    "  st.chat_message(CHAT_ROLE.user).markdown(prompt)\n",
    "  stream = generate_response(prompt, llm)\n",
    "  st.chat_message(CHAT_ROLE.assistant).write(stream)\n",
    "  \n",
    "  render_last_msg_opt_btns()\n",
    "  \n",
    "def render_chat_messages_on_rerun(\n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  for msg in llm.chat_history:\n",
    "    msg: Union[prompts.AIMessage, prompts.HumanMessage]\n",
    "    st.chat_message(msg.type).markdown(msg.content)\n",
    "\n",
    "def on_click_btn_clear_chat_history(\n",
    "  llm: agents.MyAgent,\n",
    "):\n",
    "  llm.clear_chat_history()\n",
    "  del st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]]\n",
    "  st.toast(\":orange[History cleared]\", icon=\"üóëÔ∏è\")\n",
    "\n",
    "def on_click_btn_new_chat(\n",
    "  \n",
    "):\n",
    "  st.toast(\":green[Chat created]\", icon=\"‚úÖ\")\n",
    "\n",
    "\n",
    "def on_click_btn_clear_chat(\n",
    "  \n",
    "):\n",
    "  st.toast(\":red[Chat cleared]\", icon=\"‚ùå\")\n",
    "\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "llm = chat_models.chat_openai\n",
    "\n",
    "tool_search = agent_tools.TavilySearchResults(max_results=3)\n",
    "tools = [\n",
    "  tool_search,\n",
    "]\n",
    "\n",
    "prompt = prompts.create_prompt_tool_calling_agent()\n",
    "\n",
    "llm: agents.MyAgent = create_agent(\n",
    "  _llm=llm, \n",
    "  _tools=tools, \n",
    "  _prompt=prompt, \n",
    "  _agent_type=\"tool_calling\"\n",
    ")\n",
    "\n",
    "#*==============================================================================\n",
    "\n",
    "containter_empty_btn_opts_holder = st.empty()\n",
    "\n",
    "\n",
    "render_chat_messages_on_rerun(llm=llm)\n",
    "\n",
    "with st.sidebar:\n",
    "  btn_new_chat = st.button(\n",
    "    label=\"üí¨\", \n",
    "    key=STATES[\"BTN_NEW_CHAT\"][\"KEY\"],\n",
    "    help=\"Create new Chat\",\n",
    "    on_click=on_click_btn_new_chat, \n",
    "    kwargs=dict()\n",
    "  )\n",
    "  \n",
    "  selected_chat = st.selectbox(\n",
    "    label=\"Chat\",\n",
    "    label_visibility=\"collapsed\",\n",
    "    help=\"Select Your Chat\",\n",
    "    placeholder=\"Chats\",\n",
    "    options=[\n",
    "      None,\n",
    "      \"Dummy Chat 1\",\n",
    "      \"Dummy Chat 2\",\n",
    "    ],\n",
    "    key=STATES[\"SELECTED_CHAT\"][\"KEY\"],\n",
    "  )\n",
    "  \n",
    "  prompt_example = st.selectbox(\n",
    "    label=\"Examples\",\n",
    "    label_visibility=\"collapsed\",\n",
    "    help=\"Example prompts\",\n",
    "    placeholder=\"Examples\",\n",
    "    options=[\n",
    "      None,\n",
    "      \"Hello\",\n",
    "      \"My name is Bob\",\n",
    "      \"What is my name?\",\n",
    "      \"Tell me a super long story about a dog\",\n",
    "      \"What is the question I just asked you?\",\n",
    "    ],\n",
    "    key=STATES[\"PROMPT_EXAMPLE\"][\"KEY\"],\n",
    "  )  \n",
    "  \n",
    "  #*----------------------------------------------------------------------------\n",
    "  \n",
    "  cols_clear = st.columns([0.25, 0.25, 0.5])\n",
    "  \n",
    "  btn_clear_chat_history = cols_clear[0].button(\n",
    "    label=\"üóëÔ∏è\", \n",
    "    help=\"Clear Chat History\",\n",
    "    key=STATES[\"BTN_CLEAR_CHAT_HISTORY\"][\"KEY\"],\n",
    "    on_click=on_click_btn_clear_chat_history, \n",
    "    kwargs=dict(llm=llm)\n",
    "  )\n",
    "  \n",
    "  btn_clear_chat = cols_clear[1].button(\n",
    "    label=\"‚ùå\", \n",
    "    help=\"Clear Chat\",\n",
    "    key=STATES[\"BTN_CLEAR_CHAT\"][\"KEY\"],\n",
    "    on_click=on_click_btn_clear_chat, \n",
    "    kwargs=dict()\n",
    "  )\n",
    "  \n",
    "#*----------------------------------------------------------------------------\n",
    "\n",
    "prompt: Union[str, None]\n",
    "prompt = st.chat_input(\"Say something\")\n",
    "\n",
    "if prompt_example:\n",
    "  prompt = prompt_example\n",
    "  del st.session_state[STATES[\"PROMPT_EXAMPLE\"][\"KEY\"]]\n",
    "  \n",
    "if prompt:\n",
    "  process_on_user_input(prompt=prompt, llm=llm)\n",
    "\n",
    "#*------------------------------------------------------------------------------\n",
    "# Feedback\n",
    "\n",
    "if st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]]:\n",
    "  run_url = get_LC_run_url(st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]])\n",
    "  \n",
    "  if run_url is None:\n",
    "    pass\n",
    "  \n",
    "  feedback = streamlit_feedback(\n",
    "    feedback_type=\"faces\",\n",
    "    optional_text_label=\"[Optional] Please provide an explanation\",\n",
    "    key=f'feedback_{st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]]}'\n",
    "  )\n",
    "  \n",
    "  if feedback:\n",
    "    scores = {\"üòÄ\": 1, \"üôÇ\": 0.75, \"üòê\": 0.5, \"üôÅ\": 0.25, \"üòû\": 0}\n",
    "    \n",
    "    CLIENT_LC.create_feedback(\n",
    "      st.session_state[STATES[\"LAST_RUN\"][\"KEY\"]],\n",
    "      feedback[\"type\"],\n",
    "      score=scores[feedback[\"score\"]],\n",
    "      comment=feedback.get(\"text\", None)\n",
    "    )\n",
    "    \n",
    "    st.toast(\"Feedback recorded.\", icon=\"üìù\")\n",
    "\n",
    "# st.write(st.session_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
