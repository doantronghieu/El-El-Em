{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from pytube import YouTube\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def get_youtube_script(video_url: str) -> tuple[str, str, str]:\n",
    "    try:\n",
    "        # Extract video ID from URL\n",
    "        if \"v=\" in video_url:\n",
    "            video_id = video_url.split(\"v=\")[1]\n",
    "        else:\n",
    "            split_url = video_url.split(\"/\")\n",
    "            video_id = split_url[-1].split(\"?\")[0]\n",
    "\n",
    "        # Get video title and channel name\n",
    "        yt = YouTube(video_url)\n",
    "        title = yt.title\n",
    "        channel = yt.author\n",
    "\n",
    "        # Get transcript\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        script = ' '.join([entry['text'] for entry in transcript])\n",
    "\n",
    "        return title, channel, script\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. video_url: `{video_url}`\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def extract_n_save_info(yaml_file: str):\n",
    "    # Load the YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        videos = yaml.safe_load(file)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        title, channel, _ = get_youtube_script(video['url'])\n",
    "        if title and channel:\n",
    "            video['title'] = title\n",
    "            video['channel'] = channel\n",
    "\n",
    "    # Save the updated data back to the YAML file\n",
    "    with open(yaml_file, 'w') as file:\n",
    "        yaml.dump(videos, file)\n",
    "\n",
    "def process_title(title: str) -> str:\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    import re\n",
    "    processed_title = re.sub(r'[^\\w\\s-]', '', title)\n",
    "    processed_title = re.sub(r'\\s+', '_', processed_title)\n",
    "    return processed_title.lower()\n",
    "\n",
    "def process_videos(yaml_file: str):\n",
    "    # Load the YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        videos: list = yaml.safe_load(file)\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        if 'title' in video:\n",
    "            video['title'] = process_title(video['title'])\n",
    "        \n",
    "        # Fetch channel info if missing\n",
    "        if 'channel' not in video or video['channel'] is None:\n",
    "            _, channel, _ = get_youtube_script(video['url'])\n",
    "            video['channel'] = channel\n",
    "\n",
    "    # Sort the list of videos based on the 'channel' key, handling None values\n",
    "    videos.sort(key=lambda x: (x['channel'] is None, x['channel']))\n",
    "\n",
    "    # Save the sorted data back to the YAML file\n",
    "    with open(yaml_file, 'w') as file:\n",
    "        yaml.dump(videos, file)\n",
    "\n",
    "\n",
    "def save_youtube_script(video_url: str, output_file: str):\n",
    "\ttitle, channel, script = get_youtube_script(video_url)\n",
    "\tif script:\n",
    "\t\twith open(output_file, 'w', encoding='utf-8') as file:\n",
    "\t\t\t\tfile.write(f\"Title: {title}\\nChannel: {channel}\\nScript: {script}\\n\\n\")\n",
    "\n",
    "def save_youtube_scripts(yaml_file: str, output_file: str, duration_limit: int):\n",
    "    # Split the output file into directory and file name\n",
    "    directory = os.path.dirname(output_file)\n",
    "    base_name, extension = os.path.splitext(os.path.basename(output_file))\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Load the YAML file\n",
    "    with open(yaml_file, 'r') as file:\n",
    "        videos = yaml.safe_load(file)\n",
    "\n",
    "    total_duration = 0\n",
    "    file_index = 0\n",
    "    current_file = os.path.join(directory, f'{base_name}_{file_index}{extension}')\n",
    "    file_handle = open(current_file, 'w', encoding='utf-8')\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        title, channel, script = get_youtube_script(video['url'])\n",
    "        if title and channel and script:\n",
    "            video_duration = video['length']\n",
    "            if total_duration + video_duration > duration_limit:\n",
    "                file_handle.close()\n",
    "                file_index += 1\n",
    "                current_file = os.path.join(directory, f'{base_name}_{file_index}{extension}')\n",
    "                file_handle = open(current_file, 'w', encoding='utf-8')\n",
    "                total_duration = 0\n",
    "\n",
    "            file_handle.write(f\"Title: {title}\\nChannel: {channel}\\nScript: {script}\\n\\n\" + \"-\"*80 + \"\\n\\n\")\n",
    "            total_duration += video_duration\n",
    "            video['title'] = title\n",
    "            video['channel'] = channel\n",
    "\n",
    "    file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_n_save_info(\n",
    "#     yaml_file=\"tmp/script_urls/prompt_engineering.yaml\",\n",
    "# )\n",
    "\n",
    "# process_videos(\n",
    "# \tyaml_file=\"tmp/script_urls/prompt_engineering.yaml\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_youtube_scripts(\n",
    "\tyaml_file=\"tmp/script_urls/prompt_engineering.yaml\",\n",
    "\toutput_file=\"./tmp/scripts/prompt_engineering/youtube_scripts.txt\",\n",
    "\tduration_limit=60,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import config\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=vU2S6dVf79M\"\n",
    "script = get_youtube_script(youtube_url)\n",
    "\n",
    "with open(\"./data/llm_input.txt\", 'w', encoding='utf-8') as file:\n",
    "    file.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/llm_input.txt'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Split the content into paragraphs based on the newline character\n",
    "paragraphs = content.split('\\n\\n')\n",
    "\n",
    "# Remove empty paragraphs\n",
    "paragraphs = [paragraph.strip()\n",
    "              for paragraph in paragraphs if paragraph.strip()]\n",
    "\n",
    "# gpt-3.5-turbo-0125, gpt-3.5-turbo-instruct\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "\n",
    "template = \"\"\"\\\n",
    "Your output should use the following template:\n",
    "\n",
    "# Keywords/Entities/Concepts/Complex Words\n",
    "\n",
    "## Name\n",
    "- Definition: Explanation, Core Meaning,  Key Features, Essential Attributes, Distinguishing Traits\n",
    "- Types: Varieties, Classifications, Different Forms\n",
    "- Usage: Practical Applications, Common Scenarios, Real-world Examples\n",
    "- Benefits, Challenges/Limitations/Issues\n",
    "- Others: Additional Insights, Miscellaneous Information, Noteworthy Details, History, Related Concepts\n",
    "\n",
    "# Techniques\n",
    "\n",
    "## Name\n",
    "- Description: Overview of the technique. Explanation of the fundamental concept/idea behind the technique.\n",
    "- Components: Breakdown of the key elements or parts involved in the technique.\n",
    "- Pipeline: Stages/Steps that outline the process flow of the technique, illustrating how data or tasks move through the system.\n",
    "- Implementation: Details on how to apply or integrate the technique. Recommended guidelines, strategies, Best Practices for using the technique effectively.\n",
    "- Use Cases: Examples and scenarios where the technique is particularly useful.\n",
    "- Advantages: Discussion of the benefits and strengths of the technique.\n",
    "- Limitations: Identification of any drawbacks or constraints associated with the technique. Potential mistakes or issues to be aware of when implementing the technique.\n",
    "\n",
    "Apply the following guidelines:\n",
    "- Create a detailed summary of the YouTube video using its transcription.\n",
    "- Extract important keywords from the transcript.\n",
    "- Identify complex words that may be unfamiliar to the average reader.\n",
    "- Extract techniques mentioned in the video.\n",
    "- If a keyword and a technique share the same name, combine them into one section.\n",
    "- Ensure that explanations are derived from the entire script.\n",
    "- Provide a comprehensive and clear understanding of the video's content.\n",
    "- Don't make it up. Only output content from the script only.\n",
    "\n",
    "Here is the script:\n",
    "{text}\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "chain = prompt_template | model\n",
    "\n",
    "output_file_path = './data/llm_output.txt'\n",
    "with open(output_file_path, 'a', encoding='utf-8') as f:\n",
    "  for i in tqdm(range(len(paragraphs))):\n",
    "    result = chain.invoke({\"text\": paragraphs[i]}).content\n",
    "    f.writelines(result + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
