{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_packages\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "\n",
    "from toolkit import sql\n",
    "from toolkit.langchain import (\n",
    "\ttext_embedding_models, stores, prompts, output_parsers, agents, runnables,\n",
    "\tchains, models, tools, graphs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = models.chat_openai\n",
    "vectorstore = stores.faiss.FAISS\n",
    "embeddings = text_embedding_models.OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How-to](https://python.langchain.com/v0.2/docs/how_to/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chain runnables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stream runnables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## invoke runnables in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add default invocation args to runnables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## turn any function into a runnable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pass through inputs from one chain step to the next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configure runnable behavior at runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add message history (memory) to a chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## route between sub-chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "#*==============================================================================\n",
    "categories = ['cars', 'animals']\n",
    "\n",
    "chain_1 = PromptTemplate.from_template(\n",
    "\t\"\"\"You are an expert in cars. \\\n",
    "Always answer questions starting with \"As a car expert, I can tell you that\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ") | llm\n",
    "chain_2 = PromptTemplate.from_template(\n",
    "\t\"\"\"You are an expert in animals. \\\n",
    "Always answer questions starting with \"As an animal expert, I can tell you that\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ") | llm\n",
    "\n",
    "rules = {\n",
    "\t\"cars\": chain_1,\n",
    "\t\"animals\": chain_2,\n",
    "}\n",
    "#*==============================================================================\n",
    "def create_prompt_tpl_extract_category(categories: list[str]):\n",
    "\tcategories = \", \".join([f\"{cate}\" for cate in categories])\n",
    " \n",
    "\tprompt_tpl_extract_category = \"\"\"\\\n",
    "You will be given a list of categories and a question. Your task is to determine which category the question falls into and respond with only the name of that category. Do not include any other words in your response.\n",
    "\n",
    "Here is the list of categories:\n",
    "<categories>\n",
    "{{CATEGORIES}}\n",
    "</categories>\n",
    "\n",
    "Here is the question to classify:\n",
    "<question>\n",
    "{{QUESTION}}\n",
    "</question>\n",
    "\n",
    "<example>\n",
    "<categories>\n",
    "science, history, math, literature\n",
    "</categories>\n",
    "\n",
    "<question>\n",
    "What is the chemical formula for water?\n",
    "</question>\n",
    "\n",
    "science\n",
    "</example>\n",
    "\n",
    "Now classify the provided question into one of the given categories. Remember, respond with only a single word - the name of the category.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\n",
    "\"\"\"\n",
    "\n",
    "\tprompt_tpl_extract_category = prompt_tpl_extract_category.replace(\"{{CATEGORIES}}\", categories)\n",
    "\treturn prompt_tpl_extract_category\n",
    "\n",
    "prompt_tpl_extract_category = create_prompt_tpl_extract_category(categories)\n",
    "prompt_extract_category = PromptTemplate.from_template(prompt_tpl_extract_category)\n",
    "chain_extract_category = (\n",
    "\tprompt_extract_category\n",
    "\t| llm\n",
    "\t| StrOutputParser()\n",
    ")\n",
    "\n",
    "def route_chains(chain_vars):\n",
    "\tfor cat, chain in rules.items():\n",
    "\t\tif cat.lower() == chain_vars[\"category\"]:\n",
    "\t\t\treturn chain\n",
    "\n",
    "chain_routed = (\n",
    "\t{\n",
    "\t\t\"question\": lambda x: x[\"question\"],\n",
    "\t\t\"category\": chain_extract_category,\n",
    "\t}\n",
    "\t| RunnableLambda(route_chains)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "from langchain_core.language_models.chat_models import  BaseChatModel\n",
    "\n",
    "class MyRoutableChain:\n",
    "    def __init__(\n",
    "      self, \n",
    "      categories: list[str], \n",
    "      chains: dict[str, Runnable],\n",
    "      llm: BaseChatModel,\n",
    "    ):\n",
    "        self.llm = llm\n",
    "      \n",
    "        self.categories = categories\n",
    "        self.chains = chains\n",
    "        \n",
    "        self.prompt_tpl_extract_category = self.create_prompt_tpl_extract_category()\n",
    "        self.prompt_extract_category = PromptTemplate.from_template(self.prompt_tpl_extract_category)\n",
    "        \n",
    "        self.chain_extract_category = (\n",
    "            self.prompt_extract_category\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        self.chain_routable = (\n",
    "            {\n",
    "                \"question\": lambda x: x[\"question\"],\n",
    "                \"category\": self.chain_extract_category,\n",
    "            }\n",
    "            | RunnableLambda(self.route_chains)\n",
    "        )\n",
    "\n",
    "    def create_prompt_tpl_extract_category(self):\n",
    "        categories = \", \".join([f\"{cate}\" for cate in self.categories])\n",
    "        prompt_tpl_extract_category = \"\"\"\\\n",
    "        You will be given a list of categories and a question. Your task is to determine which category the question falls into and respond with only the name of that category. Do not include any other words in your response.\n",
    "\n",
    "        Here is the list of categories:\n",
    "        <categories>\n",
    "        {{CATEGORIES}}\n",
    "        </categories>\n",
    "\n",
    "        Here is the question to classify:\n",
    "        <question>\n",
    "        {{QUESTION}}\n",
    "        </question>\n",
    "\n",
    "        <example>\n",
    "        <categories>\n",
    "        science, history, math, literature\n",
    "        </categories>\n",
    "\n",
    "        <question>\n",
    "        What is the chemical formula for water?\n",
    "        </question>\n",
    "\n",
    "        science\n",
    "        </example>\n",
    "\n",
    "        Now classify the provided question into one of the given categories. Remember, respond with only a single word - the name of the category.\n",
    "\n",
    "        <question>\n",
    "        {question}\n",
    "        </question>\n",
    "\n",
    "        Classification:\n",
    "        \"\"\"\n",
    "\n",
    "        prompt_tpl_extract_category = prompt_tpl_extract_category.replace(\"{{CATEGORIES}}\", categories)\n",
    "        return prompt_tpl_extract_category\n",
    "\n",
    "    def route_chains(self, chain_vars):\n",
    "        for cat, chain in self.chains.items():\n",
    "            if cat.lower() == chain_vars[\"category\"]:\n",
    "                return chain\n",
    "    \n",
    "    def get_chain(self):\n",
    "        return self.chain_routable\n",
    "\n",
    "\n",
    "\n",
    "#*==============================================================================\n",
    "categories = ['cars', 'animals']\n",
    "\n",
    "chain_1 = PromptTemplate.from_template(\n",
    "\t\"\"\"You are an expert in cars. \\\n",
    "Always answer questions starting with \"As a car expert, I can tell you that\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ") | llm\n",
    "chain_2 = PromptTemplate.from_template(\n",
    "\t\"\"\"You are an expert in animals. \\\n",
    "Always answer questions starting with \"As an animal expert, I can tell you that\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ") | llm\n",
    "\n",
    "rules = {\n",
    "\t\"cars\": chain_1,\n",
    "\t\"animals\": chain_2,\n",
    "}\n",
    "\n",
    "my_chain_routable = MyRoutableChain(categories, rules, llm).get_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As a car expert, I can tell you that the fastest car currently is the Bugatti Chiron Super Sport 300+, which has a top speed of over 300 mph.', response_metadata={'finish_reason': 'stop'}, id='run-104e1284-cc20-4e62-883b-14e15085b26e-0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_chain_routable.invoke({\n",
    "  \"question\": \"What is the fastest car?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a dynamic (self-constructing) chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect runnables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add fallbacks to a runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "\n",
    "- [ ] _"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
