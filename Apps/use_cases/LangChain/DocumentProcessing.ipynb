{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"notebookRunGroups": {
					"groupValue": "1"
				}
			},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"/opt/homebrew/Caskroom/miniconda/base/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
						"  from .autonotebook import tqdm as notebook_tqdm\n"
					]
				}
			],
			"source": [
				"import yaml\n",
				"import add_packages\n",
				"from pprint import pprint\n",
				"import os, re\n",
				"import pandas as pd\n",
				"# import tqdm\n",
				"from tqdm.auto import tqdm\n",
				"\n",
				"from toolkit.langchain import (\n",
				"\tdocument_loaders, text_splitters, text_embedding_models, vectorstores, \n",
				"\tchat_models, prompts, utils, output_parsers, agents, documents, llms,\n",
				"\trunnables, agent_tools\n",
				")\n",
				"\n",
				"PATH_DATA = f\"{add_packages.APP_PATH}/data/...\"\n",
				"FILE_CFG = \"....yaml\"\n",
				"tqdm.pandas(desc=\"Processing\")\n",
				"\n",
				"with open(f\"{add_packages.APP_PATH}/my_configs/{FILE_CFG}\", 'r') as file:\n",
				"    configs = yaml.safe_load(file)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Data"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt - FAQ"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## csv"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_csv = \"...\"\n",
				"path_csv = f\"{PATH_DATA}/{file_csv}\"\n",
				"path_csv_processed = f\"{PATH_DATA}/{file_csv.split('.')[0]}1.csv\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(\n",
				"\tpath_csv, delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = chat_models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				").assign(\n",
				"  text=chain2\n",
				")\n",
				"\n",
				"def process_csv_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"query = '...'\n",
				"result = process_csv_col(query)\n",
				"\n",
				"pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(path_csv)\n",
				"\n",
				"col_to_process = \"...\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_csv_col)\n",
				"\n",
				"df.to_csv(f\"{PATH_DATA}/{path_csv_processed}\", index=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_csv = path_csv_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"csv_cols = utils.get_csv_column_names(path_csv)\n",
				"\n",
				"loader_csv = document_loaders.CSVLoader(\n",
				"\tpath_csv,\n",
				"\t# source_column=\"No\",\n",
				"\tcsv_args={\n",
				"\t\t\"delimiter\": \",\", # \",\", \";\"\n",
				"\t\t# \"quotechar\": \"''\",\n",
				"\t\t\"fieldnames\": csv_cols,\n",
				"\t},\n",
				")\n",
				"docs_csv = loader_csv.load()[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"...\"\n",
				"}\n",
				"\n",
				"utils.remove_metadata(docs_csv, \"source\")\n",
				"utils.remove_metadata(docs_csv, \"row\")\n",
				"utils.update_metadata(docs_csv, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_csv = \"...\"\n",
				"path_csv = f\"{PATH_DATA}/{file_csv}\"\n",
				"path_csv_processed = f\"{file_csv.split('.')[0]}1.csv\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(\n",
				"\tpath_csv, delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = chat_models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				").assign(\n",
				"  text=chain2\n",
				")\n",
				"\n",
				"def process_csv_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"query = '...'\n",
				"result = process_csv_col(query)\n",
				"\n",
				"pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_csv(path_csv)\n",
				"\n",
				"col_to_process = \"...\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_csv_col)\n",
				"\n",
				"df.to_csv(f\"{PATH_DATA}/{path_csv_processed}\", index=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_csv = path_csv_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"csv_cols = utils.get_csv_column_names(path_csv)\n",
				"\n",
				"loader_csv = document_loaders.CSVLoader(\n",
				"\tpath_csv,\n",
				"\t# source_column=\"No\",\n",
				"\tcsv_args={\n",
				"\t\t\"delimiter\": \",\", # \",\", \";\"\n",
				"\t\t# \"quotechar\": \"''\",\n",
				"\t\t\"fieldnames\": csv_cols,\n",
				"\t},\n",
				")\n",
				"docs_csv = loader_csv.load()\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"...\"\n",
				"}\n",
				"\n",
				"utils.remove_metadata(docs_csv, \"source\")\n",
				"utils.remove_metadata(docs_csv, \"row\")\n",
				"utils.update_metadata(docs_csv, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Vector store \n",
				"\n",
				"Note:\n",
				"- `tiktoken` >= 0.6.0"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## csv"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"\u001b[32m2024-05-14 10:09:10.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mFound collection: `vtc-courses-information-3072-v1`.\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:10.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1m`vtc-courses-information-3072-v1` - Embeddings: openai - {'model': 'text-embedding-3-large'}, 3072\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:10.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m`vtc-courses-information-3072-v1` - Retriever: Vectorstore\u001b[0m\n"
					]
				}
			],
			"source": [
				"qdrant_csv = vectorstores.QdrantWrapper(\n",
				"\tqdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"\tqdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"\tconfigs=configs,\n",
				"\t**configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_csv.add_documents(docs_csv)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"\u001b[32m2024-05-14 10:09:10.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mFound collection: `vtc-courses-information-3072-v1`.\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:10.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1m`vtc-courses-information-3072-v1` - Embeddings: openai - {'model': 'text-embedding-3-large'}, 3072\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:10.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m`vtc-courses-information-3072-v1` - Retriever: Vectorstore\u001b[0m\n"
					]
				}
			],
			"source": [
				"qdrant_csv = vectorstores.QdrantWrapper(\n",
				"\tqdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"\tqdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"\tconfigs=configs,\n",
				"\t**configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_csv.add_documents(docs_csv)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"notebookRunGroups": {
					"groupValue": "2"
				}
			},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"\u001b[32m2024-05-14 10:09:07.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mFound collection: `vtc-faq-3072-v1`.\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:07.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1m`vtc-faq-3072-v1` - Embeddings: openai - {'model': 'text-embedding-3-large'}, 3072\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:07.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m`vtc-faq-3072-v1` - Retriever: Vectorstore\u001b[0m\n"
					]
				}
			],
			"source": [
				"qdrant_txt = vectorstores.QdrantWrapper(\n",
				"  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"  configs=configs,\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt.add_documents(docs_txt)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"\u001b[32m2024-05-14 10:09:07.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1mFound collection: `vtc-faq-3072-v1`.\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:07.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1m`vtc-faq-3072-v1` - Embeddings: openai - {'model': 'text-embedding-3-large'}, 3072\u001b[0m\n",
						"\u001b[32m2024-05-14 10:09:07.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtoolkit.langchain.vectorstores\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m`vtc-faq-3072-v1` - Retriever: Vectorstore\u001b[0m\n"
					]
				}
			],
			"source": [
				"qdrant_txt = vectorstores.QdrantWrapper(\n",
				"  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"  configs=configs,\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# qdrant_txt.add_documents(docs_txt)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Test"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = chat_models.chat_openai\n",
				"\n",
				"tools = [\n",
				"\tagent_tools.TavilySearchResults(max_results=3),\n",
				"\tqdrant_txt.retriever_tool,\n",
				"\tqdrant_csv.retriever_tool,\n",
				"]\n",
				"\n",
				"system_message_custom = configs[\"prompts\"][\"system_message_onlinica\"]\n",
				"prompt = prompts.create_prompt_tool_calling_agent(system_message_custom)\n",
				"\n",
				"agent = agents.MyStatelessAgent(\n",
				"\tllm=llm,\n",
				"\ttools=tools,\n",
				"\tprompt=prompt,\n",
				"\tagent_type=configs[\"agents\"][\"type\"],\n",
				"\tagent_verbose=False,\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = [\n",
				"\n",
				"]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n",
						"\n",
						"\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
						"\u001b[32;1m\u001b[1;3mXin lỗi vì sự nhầm lẫn trước đó. Tên của bạn là Bob. Có điều gì tôi có thể giúp bạn hôm nay không, Bob?\u001b[0m\n",
						"\n",
						"\u001b[1m> Finished chain.\u001b[0m\n",
						"('Xin lỗi vì sự nhầm lẫn trước đó. Tên của bạn là Bob. Có điều gì tôi có thể '\n",
						" 'giúp bạn hôm nay không, Bob?')\n"
					]
				}
			],
			"source": [
				"input_message = questions[1]\n",
				"# await agent.stream_conversable_agent(questions[2])\n",
				"result = agent.invoke_agent(input_message)\n",
				"# await agent.stream_agent(input_message)\n",
				"pprint(result)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "LLM",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.8"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
