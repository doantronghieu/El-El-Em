{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"notebookRunGroups": {
					"groupValue": "1"
				}
			},
			"outputs": [],
			"source": [
				"import yaml\n",
				"import add_packages\n",
				"from pprint import pprint\n",
				"import os, re\n",
				"import pandas as pd\n",
				"# import tqdm\n",
				"from tqdm.auto import tqdm\n",
				"\n",
				"from toolkit.langchain import (\n",
				"\tdocument_loaders, text_splitters, text_embedding_models, stores, \n",
				"\tprompts, utils, output_parsers, agents, documents, models,\n",
				"\trunnables, tools, chains\n",
				")\n",
				"\n",
				"from toolkit import sql\n",
				"\n",
				"PATH_DATA = f\"{add_packages.APP_PATH}/data/...\"\n",
				"FILE_CFG = \"....yaml\"\n",
				"tqdm.pandas(desc=\"Processing\")\n",
				"\n",
				"with open(f\"{add_packages.APP_PATH}/my_configs/{FILE_CFG}\", 'r') as file:\n",
				"    configs = yaml.safe_load(file)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = models.chat_openai\n",
				"my_sql_db = sql.MySQLDatabase()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"all_proper_nouns = []"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Data"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt - FAQ"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## table"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_xlsx = \"...\"\n",
				"path_xlsx = f\"{PATH_DATA}/{file_xlsx}\"\n",
				"path_xlsx_processed = f\"{PATH_DATA}/{file_xlsx.split('.')[0]}1.xlsx\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(\n",
				"\tpath_xlsx, \n",
				" \t# delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()\n",
				"\n",
				"# Prompting to get new col names\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				").assign(\n",
				"  text=chain2\n",
				")\n",
				"\n",
				"def process_xlsx_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"def capitalize_first_letter(s):\n",
				"\treturn ' '.join([word.capitalize() for word in s.split()])\n",
				"\n",
				"def change_col_value(df: pd.DataFrame, column_name: str, value, new_value):\n",
				"\tdf[column_name] = df[column_name].replace(value, new_value)\n",
				"\treturn df\n",
				"\n",
				"def replace_col_value_if_contains(df, column_name, substring, new_substring):\n",
				"\tdf[column_name] = df[column_name].str.replace(substring, new_substring)\n",
				"\treturn df\n",
				"\n",
				"# query = '...'\n",
				"# result = process_xlsx_col(query)\n",
				"\n",
				"# pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"col_to_process = \"...\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_xlsx_col)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# df.to_excel(f\"{path_xlsx_processed}\", index=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_xlsx = path_xlsx_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load to sql"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_table_schema = [\n",
				"\t\"course_id SERIAL\",\n",
				"\t\"course_name VARCHAR(255) NOT NULL UNIQUE\",\n",
				"\t\"course_category VARCHAR(255) NOT NULL\",\n",
				"\t\"instructor_name VARCHAR(100) NOT NULL\",\n",
				"\t\"course_link VARCHAR(2048) NOT NULL UNIQUE\",\n",
				"\t\"course_description TEXT NOT NULL\",\n",
				"\t\"PRIMARY KEY (course_id)\",\n",
				"]\n",
				"my_table = sql.MySQLTable(\n",
				"\tname=\"...\", \n",
				"\tschema=my_table_schema,\n",
				"\tdb=my_sql_db,\n",
				")\n",
				"my_table.create()\n",
				"\n",
				"db = stores.SQLDatabase.from_uri(my_sql_db.get_uri())\n",
				"\n",
				"table_cols = [col_description.split(\" \")[0] for col_description in my_table_schema][1:-1]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# my_table.insert_from_dataframe(df)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(path_xlsx)\n",
				"df.columns = table_cols\n",
				"\n",
				"cols = [...] # table_cols\n",
				"proper_nouns = [value for col in cols for value in my_table.get_discrete_values_col(col)]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = ...\n",
				"examples_questions_to_sql = ..."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Vector store \n",
				"\n",
				"Note:\n",
				"- `tiktoken` >= 0.6.0"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt = stores.QdrantWrapper(\n",
				"  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"  configs=configs,\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt.add_documents(docs_txt)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt = stores.QdrantWrapper(\n",
				"  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"  configs=configs,\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# qdrant_txt.add_documents(docs_txt)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Test"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"examples_fewshot_tmp = dict(configs[\"sql\"][\"examples_questions_to_sql\"]).values()\n",
				"examples_questions_to_sql = [example for sublist in examples_fewshot_tmp for example in sublist]\n",
				"\n",
				"proper_nouns = configs[\"sql\"][\"proper_nouns\"]\n",
				"\n",
				"my_sql_db = sql.MySQLDatabase()\n",
				"\n",
				"cfg_sql = configs[\"sql\"]\n",
				"cfg_sql_tool = cfg_sql[\"tool\"]\n",
				"cfg_sql_params = cfg_sql[\"params\"]\n",
				"\n",
				"my_sql_chain = chains.MySqlChain(\n",
				"\tmy_sql_db=my_sql_db,\n",
				"\tllm=llm,\n",
				"\tembeddings=embeddings,\n",
				"\tvectorstore=vectorstore,\n",
				"\tproper_nouns=proper_nouns,\n",
				"\tk_retriever_proper_nouns=4,\n",
				"\texamples_questions_to_sql=examples_questions_to_sql,\n",
				"\tk_few_shot_examples=cfg_sql_params[\"k_few_shot_examples\"],\n",
				"\tsql_max_out_length=cfg_sql_params[\"sql_max_out_length\"],\n",
				"\tis_sql_get_all=cfg_sql_params[\"is_sql_get_all\"],\n",
				"\tis_debug=False,\n",
				"\ttool_name=cfg_sql_tool[\"name\"],\n",
				"\ttool_description=cfg_sql_tool[\"description\"],\n",
				"\ttool_metadata=cfg_sql_tool[\"metadata\"],\n",
				"\ttool_tags=cfg_sql_tool[\"tags\"],\n",
				")\n",
				"\n",
				"tool_chain_sql = my_sql_chain.create_tool_chain_sql()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = models.chat_openai\n",
				"\n",
				"tools = [\n",
				"\t# tools.TavilySearchResults(max_results=3),\n",
				"\tqdrant_txt.retriever_tool,\n",
				"\ttool_chain_sql.retriever_tool,\n",
				"]\n",
				"\n",
				"system_message_custom = configs[\"prompts\"][\"system_message_vtc\"]\n",
				"prompt = prompts.create_prompt_tool_calling_agent(system_message_custom)\n",
				"\n",
				"agent = agents.MyStatelessAgent(\n",
				"\tllm=llm,\n",
				"\ttools=tools,\n",
				"\tprompt=prompt,\n",
				"\tagent_type=configs[\"agents\"][\"type\"],\n",
				"\tagent_verbose=False,\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = [\n",
				"\n",
				"]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"res = []\n",
				"async for chunk in agent.astream_events_basic(\n",
				"\t# \"QUESTION\",\n",
				"  show_tool_call=True,\n",
				"  history_type=\"in_memory\",\n",
				"):\n",
				"\tprint(chunk, end=\"\", flush=True)\n",
				"\n",
				"\tres.append(chunk)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"input_message = questions[1]\n",
				"result = agent.invoke_agent(input_message)\n",
				"# await agent.stream_agent(input_message)\n",
				"pprint(result)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "LLM",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.9"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
