{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"notebookRunGroups": {
					"groupValue": "1"
				}
			},
			"outputs": [],
			"source": [
				"import yaml\n",
				"import add_packages\n",
				"from pprint import pprint\n",
				"import os, re\n",
				"import pandas as pd\n",
				"# import tqdm\n",
				"from tqdm.auto import tqdm\n",
				"\n",
				"from toolkit.langchain import (\n",
				"\tdocument_loaders, text_splitters, text_embedding_models, stores, \n",
				"\tprompts, utils, output_parsers, agents, documents, models,\n",
				"\trunnables, tools, chains\n",
				")\n",
				"\n",
				"from toolkit import sql\n",
				"\n",
				"PATH_DATA = f\"{add_packages.APP_PATH}/data/...\"\n",
				"FILE_CFG = \"....yaml\"\n",
				"tqdm.pandas(desc=\"Processing\")\n",
				"\n",
				"with open(f\"{add_packages.APP_PATH}/my_configs/{FILE_CFG}\", 'r') as file:\n",
				"    configs = yaml.safe_load(file)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = models.chat_openai\n",
				"my_sql_db = sql.MySQLDatabase()\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Data"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt - FAQ"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## table"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_xlsx = \"...\"\n",
				"path_xlsx = f\"{PATH_DATA}/{file_xlsx}\"\n",
				"path_xlsx_processed = f\"{PATH_DATA}/{file_xlsx.split('.')[0]}1.xlsx\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(\n",
				"\tpath_xlsx, \n",
				" \t# delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()\n",
				"\n",
				"# Prompting to get new col names\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				").assign(\n",
				"  text=chain2\n",
				")\n",
				"\n",
				"def process_xlsx_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"def capitalize_first_letter(s):\n",
				"\treturn ' '.join([word.capitalize() for word in s.split()])\n",
				"\n",
				"query = '...'\n",
				"result = process_xlsx_col(query)\n",
				"\n",
				"pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(path_xlsx)\n",
				"\n",
				"col_to_process = \"...\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_xlsx_col)\n",
				"\n",
				"df.to_excel(f\"{path_xlsx_processed}\", index=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_xlsx = path_xlsx_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"xlsx_cols = ...\n",
				"\n",
				"loader_xlsx = document_loaders.UnstructuredExcelLoader(\n",
				"\tpath_xlsx,\n",
				"\tmode=\"elements\",\n",
				")\n",
				"docs_xlsx = loader_xlsx.load()\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"...\"\n",
				"}\n",
				"\n",
				"utils.remove_metadata(docs_xlsx, \"source\")\n",
				"utils.remove_metadata(docs_xlsx, \"row\")\n",
				"utils.update_metadata(docs_xlsx, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load to sql"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_table_schema = [\n",
				"\t\"course_id SERIAL\",\n",
				"\t\"course_name VARCHAR(255) NOT NULL UNIQUE\",\n",
				"\t\"course_category VARCHAR(255) NOT NULL\",\n",
				"\t\"instructor_name VARCHAR(100) NOT NULL\",\n",
				"\t\"course_link VARCHAR(2048) NOT NULL UNIQUE\",\n",
				"\t\"course_description TEXT NOT NULL\",\n",
				"\t\"PRIMARY KEY (course_id)\",\n",
				"]\n",
				"my_table = sql.MySQLTable(\n",
				"\tname=\"...\", \n",
				"\tschema=my_table_schema,\n",
				"\tdb=my_sql_db,\n",
				")\n",
				"my_table.create()\n",
				"\n",
				"db = stores.SQLDatabase.from_uri(my_sql_db.get_uri())\n",
				"llm = models.chat_openai\n",
				"\n",
				"embeddings = text_embedding_models.OpenAIEmbeddings()\n",
				"vectorstore = stores.faiss.FAISS\n",
				"\n",
				"table_cols = [col_description.split(\" \")[0] for col_description in my_table_schema][1:-1]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(path_xlsx)\n",
				"df.columns = table_cols\n",
				"\n",
				"my_table.insert_from_dataframe(df)\n",
				"\n",
				"cols = [...]\n",
				"proper_nouns = [value for col in cols for value in my_table.get_discrete_values_col(col)]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = ...\n",
				"examples_questions_to_sql = ..."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_xlsx = \"...\"\n",
				"path_xlsx = f\"{PATH_DATA}/{file_xlsx}\"\n",
				"path_xlsx_processed = f\"{PATH_DATA}/{file_xlsx.split('.')[0]}1.xlsx\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(\n",
				"\tpath_xlsx, \n",
				" \t# delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				").assign(\n",
				"  text=chain2\n",
				")\n",
				"\n",
				"def process_xlsx_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"query = '...'\n",
				"result = process_xlsx_col(query)\n",
				"\n",
				"pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(path_xlsx)\n",
				"\n",
				"col_to_process = \"...\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_xlsx_col)\n",
				"\n",
				"df.to_excel(f\"{path_xlsx_processed}\", index=False)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_xlsx = path_xlsx_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"xlsx_cols = ...\n",
				"\n",
				"loader_xlsx = document_loaders.UnstructuredExcelLoader(\n",
				"\tpath_xlsx,\n",
				"\tmode=\"elements\",\n",
				")\n",
				"docs_xlsx = loader_xlsx.load()\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"...\"\n",
				"}\n",
				"\n",
				"utils.remove_metadata(docs_xlsx, \"source\")\n",
				"utils.remove_metadata(docs_xlsx, \"row\")\n",
				"utils.update_metadata(docs_xlsx, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load to sql"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_table_schema = [\n",
				"\t\"course_id SERIAL\",\n",
				"\t\"course_name VARCHAR(255) NOT NULL UNIQUE\",\n",
				"\t\"course_category VARCHAR(255) NOT NULL\",\n",
				"\t\"instructor_name VARCHAR(100) NOT NULL\",\n",
				"\t\"course_link VARCHAR(2048) NOT NULL UNIQUE\",\n",
				"\t\"course_description TEXT NOT NULL\",\n",
				"\t\"PRIMARY KEY (course_id)\",\n",
				"]\n",
				"my_table = sql.MySQLTable(\n",
				"\tname=\"...\", \n",
				"\tschema=my_table_schema,\n",
				"\tdb=my_sql_db,\n",
				")\n",
				"my_table.create()\n",
				"\n",
				"db = stores.SQLDatabase.from_uri(my_sql_db.get_uri())\n",
				"llm = models.chat_openai\n",
				"\n",
				"embeddings = text_embedding_models.OpenAIEmbeddings()\n",
				"vectorstore = stores.faiss.FAISS\n",
				"\n",
				"table_cols = [col_description.split(\" \")[0] for col_description in my_table_schema][1:-1]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(path_xlsx)\n",
				"df.columns = table_cols\n",
				"\n",
				"my_table.insert_from_dataframe(df)\n",
				"\n",
				"cols = [...]\n",
				"proper_nouns = [value for col in cols for value in my_table.get_discrete_values_col(col)]\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Vector store \n",
				"\n",
				"Note:\n",
				"- `tiktoken` >= 0.6.0"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt = stores.QdrantWrapper(\n",
				"  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"  configs=configs,\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt.add_documents(docs_txt)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt = stores.QdrantWrapper(\n",
				"  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"  configs=configs,\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# qdrant_txt.add_documents(docs_txt)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## table"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_xlsx = stores.QdrantWrapper(\n",
				"\tqdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"\tqdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"\tconfigs=configs,\n",
				"\t**configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_xlsx.add_documents(docs_xlsx)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_xlsx = stores.QdrantWrapper(\n",
				"\tqdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
				"\tqdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
				"\tconfigs=configs,\n",
				"\t**configs[\"vector_db\"][\"qdrant\"][\"...\"]\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_xlsx.add_documents(docs_xlsx)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Test"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = models.chat_openai\n",
				"\n",
				"tools = [\n",
				"\ttools.TavilySearchResults(max_results=3),\n",
				"\tqdrant_txt.retriever_tool,\n",
				"\tqdrant_xlsx.retriever_tool,\n",
				"]\n",
				"\n",
				"system_message_custom = configs[\"prompts\"][\"system_message_vtc\"]\n",
				"prompt = prompts.create_prompt_tool_calling_agent(system_message_custom)\n",
				"\n",
				"agent = agents.MyStatelessAgent(\n",
				"\tllm=llm,\n",
				"\ttools=tools,\n",
				"\tprompt=prompt,\n",
				"\tagent_type=configs[\"agents\"][\"type\"],\n",
				"\tagent_verbose=False,\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = [\n",
				"\n",
				"]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"input_message = questions[1]\n",
				"# await agent.stream_conversable_agent(questions[2])\n",
				"result = agent.invoke_agent(input_message)\n",
				"# await agent.stream_agent(input_message)\n",
				"pprint(result)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "LLM",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.9"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
