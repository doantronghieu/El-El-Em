{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import add_packages\n",
				"import config\n",
				"from pprint import pprint"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from toolkit.langchain import (document_loaders, text_embedding_models, stores,\n",
				"                          text_splitters)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Vector stores\n",
				"https://python.langchain.com/docs/integrations/stores/chroma"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Basic Example\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader = document_loaders.text_loader(\"../../data/state_of_the_union.txt\")\n",
				"documents = loader.load()\n",
				"\n",
				"text_splitter = text_splitters.character_text_splitter(\n",
				"  chunk_size=1000, chunk_overlap=0,\n",
				")\n",
				"docs = text_splitter.split_documents(documents)\n",
				"\n",
				"embedding_fn = text_embedding_models.openai_embeddings()\n",
				"\n",
				"chroma_path = \"../../data/store/chroma_db\"\n",
				"db = stores.chroma_store.from_documents(\n",
				"  docs, \n",
				"  embedding_fn,\n",
				"  persist_directory=chroma_path\n",
				")\n",
				"\n",
				"query = \"What did the president say about Ketanji Brown Jackson\"\n",
				"docs = db.similarity_search(query)\n",
				"\n",
				"pprint(docs)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loaded_db = stores.chroma_store(\n",
				"  persist_directory=chroma_path, embedding_function=embedding_fn,\n",
				")\n",
				"docs = loaded_db.similarity_search(query)\n",
				"pprint(docs)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Passing a Chroma Client into Langchain\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import chromadb\n",
				"\n",
				"persistent_client = chromadb.PersistentClient()\n",
				"collection = persistent_client.get_or_create_collection(\n",
				"  \"../../data/store/chroma_db\"\n",
				")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Using the Docker Container\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Update and Delete\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Use OpenAI Embeddings\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Similarity search with score\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Retriever options\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Filtering on metadata"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Self-querying retriever\n",
				"https://python.langchain.com/docs/integrations/retrievers/self_query/chroma_self_query"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Templates"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## rag-chroma\n",
				"https://python.langchain.com/docs/templates/rag-chroma"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## rag-chroma-private\n",
				"https://python.langchain.com/docs/templates/rag-chroma-private"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## rag-chroma-multi-modal\n",
				"https://python.langchain.com/docs/templates/rag-chroma-multi-modal"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## rag-chroma-multi-modal-multi-vector\n",
				"https://python.langchain.com/docs/templates/rag-chroma-multi-modal-multi-vector"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## rag-multi-modal-local\n",
				"https://python.langchain.com/docs/templates/rag-multi-modal-local"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## rag-gemini-multi-modal\n",
				"https://python.langchain.com/docs/templates/rag-gemini-multi-modal"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## "
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "LLM",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.18"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
