{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"notebookRunGroups": {
					"groupValue": "1"
				}
			},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"/opt/homebrew/Caskroom/miniconda/base/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
						"  from .autonotebook import tqdm as notebook_tqdm\n"
					]
				}
			],
			"source": [
				"import yaml\n",
				"import add_packages\n",
				"from pprint import pprint\n",
				"import os\n",
				"import pandas as pd\n",
				"from tqdm.auto import tqdm\n",
				"\n",
				"from toolkit.langchain import (\n",
				"\tdocument_loaders, text_splitters, text_embedding_models, stores, \n",
				"\tprompts, utils, output_parsers, agents, documents, models,\n",
				"\trunnables, tools, chains\n",
				")\n",
				"\n",
				"from toolkit import sql, utils\n",
				"\n",
				"PATH_DATA = f\"{add_packages.APP_PATH}/data/tdtu/FEEE\"\n",
				"FILE_CFG = \"tdtu.yaml\"\n",
				"tqdm.pandas(desc=\"Processing\")\n",
				"\n",
				"with open(f\"{add_packages.APP_PATH}/my_configs/{FILE_CFG}\", 'r') as file:\n",
				"\tconfigs = yaml.safe_load(file)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = models.chat_openai\n",
				"embeddings = text_embedding_models.OpenAIEmbeddings()\n",
				"vectorstore = stores.faiss.FAISS"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_sql_db = sql.MySQLDatabase()\n",
				"# my_sql_db = sql.MySQLDatabase(\n",
				"# \tdbname=os.getenv(\"SQL_DB_NEON\"),\n",
				"# \thost=os.getenv(\"SQL_HOST_NEON\"),\n",
				"# \tport=os.getenv(\"SQL_PORT_NEON\"),\n",
				"# \tuser=os.getenv(\"SQL_USER_NEON\"),\n",
				"# \tpassword=os.getenv(\"SQL_PASSWORD_NEON\"),\n",
				"# )"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Data"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### tdtu_feee_faq"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/tdtu_feee_faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=1000, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"general information\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"docs_txt_tdtu_feee_faq = docs_txt"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### File 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_txt = f\"{PATH_DATA}/faq.txt\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"loader_txt = document_loaders.TextLoader(path_txt)\n",
				"doc_txt = loader_txt.load()\n",
				"\n",
				"text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
				"\t# chunk_size=500, chunk_overlap=100,\n",
				"\tseparators=[\"##\"], chunk_size=150, chunk_overlap=0,\n",
				")\n",
				"docs_txt = text_splitter.split_documents(doc_txt)\n",
				"docs_txt = docs_txt[1:]\n",
				"\n",
				"metadatas = {\n",
				"\t\"data\": \"frequently asked questions\"\n",
				"}\n",
				"utils.remove_metadata(docs_txt, \"source\")\n",
				"utils.update_metadata(docs_txt, metadatas)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## csv"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### NhanSu"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_xlsx = \"NhanSu.xlsx\"\n",
				"path_xlsx = f\"{PATH_DATA}/{file_xlsx}\"\n",
				"path_xlsx_processed = f\"{PATH_DATA}/{file_xlsx.split('.')[0]}1.xlsx\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(\n",
				"\tpath_xlsx, \n",
				" \t# delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()\n",
				"\n",
				"# Prompting to get new col names"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"# chain = runnables.RunnablePassthrough.assign(\n",
				"#   text=chain1\n",
				"# ).assign(\n",
				"#   text=chain2\n",
				"# )\n",
				"\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				")\n",
				"\n",
				"def process_xlsx_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"def capitalize_first_letter(s):\n",
				"\treturn ' '.join([word.capitalize() for word in s.split()])\n",
				"\n",
				"def change_col_value(df: pd.DataFrame, column_name: str, value, new_value):\n",
				"\tdf[column_name] = df[column_name].replace(value, new_value)\n",
				"\treturn df\n",
				"\n",
				"def replace_col_value_if_contains(df, column_name, substring, new_substring):\n",
				"\tdf[column_name] = df[column_name].str.replace(substring, new_substring)\n",
				"\treturn df\n",
				"\n",
				"# query = '...'\n",
				"# result = process_xlsx_col(query)\n",
				"\n",
				"# pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"col_to_process = \"Liên hệ\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_xlsx_col)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# df.to_excel(f\"{path_xlsx_processed}\", index=False)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_xlsx = path_xlsx_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load to sql"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_table_schema = [\n",
				"\t\"id SERIAL\",\n",
				"\t\"faculty TEXT\",\n",
				"\t\"name TEXT\",\n",
				"\t\"position TEXT\",\n",
				"\t\"major TEXT\",\n",
				"\t\"email TEXT\",\n",
				"\t\"office TEXT\",\n",
				"\t\"child_department TEXT\",\n",
				"\t\"PRIMARY KEY (id)\",\n",
				"]\n",
				"\n",
				"my_table = sql.MySQLTable(\n",
				"\tname=\"tdtu_feee_personnel\", \n",
				"\tschema=my_table_schema,\n",
				"\tdb=my_sql_db,\n",
				")\n",
				"my_table.create()\n",
				"\n",
				"db = stores.SQLDatabase.from_uri(my_sql_db.get_uri())\n",
				"\n",
				"table_cols = [col_description.split(\" \")[0] for col_description in my_table_schema][1:-1]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# my_table.insert_from_dataframe(df)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# df = pd.read_excel(path_xlsx)\n",
				"# df.columns = table_cols\n",
				"\n",
				"# my_table.insert_from_dataframe(df)\n",
				"\n",
				"# cols = ['name', 'position', 'major', 'office', 'child_department']\n",
				"# proper_nouns = [value for col in cols for value in my_table.get_discrete_values_col(col)]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# all_proper_nouns.extend(proper_nouns)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = ...\n",
				"examples_questions_to_sql = ..."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### ChuongTrinhDaoTao"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"file_xlsx = \"ChuongTrinhDaoTao.xlsx\"\n",
				"path_xlsx = f\"{PATH_DATA}/{file_xlsx}\"\n",
				"path_xlsx_processed = f\"{PATH_DATA}/{file_xlsx.split('.')[0]}1.xlsx\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df = pd.read_excel(\n",
				"\tpath_xlsx, \n",
				" \t# delimiter=\";\"\n",
				")\n",
				"\n",
				"df.head()\n",
				"\n",
				"# Prompting to get new col names"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Process"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = models.chat_openai\n",
				"\n",
				"template1 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"template2 = \"\"\"\\\n",
				"...\n",
				"{text}\n",
				"\"\"\"\n",
				"\n",
				"prompt_template1 = prompts.PromptTemplate.from_template(template1)\n",
				"prompt_template2 = prompts.PromptTemplate.from_template(template2)\n",
				"\n",
				"chain1 = prompt_template1 | model | output_parsers.StrOutputParser()\n",
				"chain2 = prompt_template2 | model | output_parsers.StrOutputParser()\n",
				"\n",
				"# chain = runnables.RunnablePassthrough.assign(\n",
				"#   text=chain1\n",
				"# ).assign(\n",
				"#   text=chain2\n",
				"# )\n",
				"\n",
				"\n",
				"chain = runnables.RunnablePassthrough.assign(\n",
				"  text=chain1\n",
				")\n",
				"\n",
				"def process_xlsx_col(text: str) -> str:\n",
				"  result = chain.invoke({\"text\": text})['text']\n",
				"  return result\n",
				"\n",
				"def capitalize_first_letter(s):\n",
				"\treturn ' '.join([word.capitalize() for word in s.split()])\n",
				"\n",
				"def change_col_value(df: pd.DataFrame, column_name: str, value, new_value):\n",
				"\tdf[column_name] = df[column_name].replace(value, new_value)\n",
				"\treturn df\n",
				"\n",
				"def replace_col_value_if_contains(df, column_name, substring, new_substring):\n",
				"\tdf[column_name] = df[column_name].str.replace(substring, new_substring)\n",
				"\treturn df\n",
				"\n",
				"# query = '...'\n",
				"# result = process_xlsx_col(query)\n",
				"\n",
				"# pprint(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"col_to_process = \"Liên hệ\"\n",
				"\n",
				"df[col_to_process] = df[col_to_process].progress_apply(process_xlsx_col)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df.to_excel(f\"{path_xlsx_processed}\", index=False)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"path_xlsx = path_xlsx_processed"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Load to sql"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_table_schema = [\n",
				"\t\"id SERIAL\",\n",
				"\t\"faculty TEXT\",\n",
				"\t\"study_field TEXT\",\n",
				"\t\"link TEXT\",\n",
				"\t\"program_type TEXT\",\n",
				"\t\"education_level TEXT\",\n",
				"\t\"introduction TEXT\",\n",
				"\t\"career_prospects TEXT\",\n",
				"\t\"outcome TEXT\",\n",
				"\t\"syllabub TEXT\",\n",
				"\t\"admission_candidates TEXT\",\n",
				"\t\"registration TEXT\",\n",
				"\t\"tuition TEXT\",\n",
				" \t\"contact TEXT\",\n",
				"\t\"PRIMARY KEY (id)\",\n",
				"]\n",
				"my_table = sql.MySQLTable(\n",
				"\tname=\"tdtu_feee_admission\", \n",
				"\tschema=my_table_schema,\n",
				"\tdb=my_sql_db,\n",
				")\n",
				"my_table.create()\n",
				"\n",
				"table_cols = [col_description.split(\" \")[0] for col_description in my_table_schema][1:-1]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# my_table.insert_from_dataframe(df)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# df = pd.read_excel(path_xlsx)\n",
				"# df.columns = table_cols\n",
				"\n",
				"# my_table.insert_from_dataframe(df)\n",
				"\n",
				"# cols = ['faculty', 'study_field', 'program_type', 'education_level']\n",
				"# proper_nouns = [value for col in cols for value in my_table.get_discrete_values_col(col)]\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# all_proper_nouns.extend(proper_nouns)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"questions = ...\n",
				"examples_questions_to_sql = ..."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Vector store "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## txt"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### tdtu_feee_faq"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"qdrant_txt_tdtu_feee_faq = stores.QdrantStore(\n",
				"  embeddings_provider=\"openai\",\n",
				"\tembeddings_model=\"text-embedding-3-large\",\n",
				"\tllm=models.chat_openai,\n",
				"\tsearch_type=\"mmr\",\n",
				"  configs=configs,\n",
				"  distance=\"Cosine\",\n",
				"  retriever_types=\"base\",\n",
				"  **configs[\"vector_db\"][\"qdrant\"][\"tdtu_feee_faq\"],\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# qdrant_txt_tdtu_feee_faq.add_documents(docs_txt_tdtu_feee_faq)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Test"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"my_chain_rag_tdtu_feee_faq = chains.MyRagChain(\n",
				"\tllm=llm,\n",
				"\tretriever=qdrant_txt_tdtu_feee_faq.retriever,\n",
				"\tis_debug=False,\n",
				"\tjust_return_ctx=True,\n",
				"\t**configs[\"vector_db\"][\"qdrant\"][\"tdtu_feee_faq\"],\n",
				")\n",
				"\n",
				"tool_chain_rag_tdtu_feee_faq = my_chain_rag_tdtu_feee_faq.create_tool_chain_rag()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"examples_fewshot_tmp = dict(configs[\"sql\"][\"examples_questions_to_sql\"]).values()\n",
				"examples_questions_to_sql = [example for sublist in examples_fewshot_tmp for example in sublist]\n",
				"\n",
				"proper_nouns = configs[\"sql\"][\"proper_nouns\"]\n",
				"\n",
				"my_sql_db = sql.MySQLDatabase()\n",
				"\n",
				"cfg_sql = configs[\"sql\"]\n",
				"cfg_sql_tool = cfg_sql[\"tool\"]\n",
				"\n",
				"my_sql_chain = chains.MySqlChain(\n",
				"\tmy_sql_db=my_sql_db,\n",
				"\tllm=llm,\n",
				"\tembeddings=embeddings,\n",
				"\tvectorstore=vectorstore,\n",
				"\tproper_nouns=proper_nouns,\n",
				"\tk_retriever_proper_nouns=4,\n",
				"\texamples_questions_to_sql=examples_questions_to_sql,\n",
				"\tk_few_shot_examples=5,\n",
				"\tsql_max_out_length=2000,\n",
				"\tis_sql_get_all=True,\n",
				"\tis_debug=False,\n",
				"\ttool_name=cfg_sql_tool[\"name\"],\n",
				"\ttool_description=cfg_sql_tool[\"description\"],\n",
				"\ttool_metadata=cfg_sql_tool[\"metadata\"],\n",
				"\ttool_tags=cfg_sql_tool[\"tags\"],\n",
				")\n",
				"\n",
				"tool_chain_sql = my_sql_chain.create_tool_chain_sql()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"llm = models.create_llm(provider=\"openai\", version=\"gpt-3.5-turbo-0125\")\n",
				"\n",
				"tools = [\n",
				"\ttool_chain_rag_tdtu_feee_faq,\n",
				"\ttool_chain_sql,\n",
				"]\n",
				"\n",
				"system_message_custom = configs[\"prompts\"][\"system_message_tdtu\"]\n",
				"prompt = prompts.create_prompt_tool_calling_agent(system_message_custom)\n",
				"\n",
				"agent = agents.MyStatelessAgent(\n",
				"\tllm=llm,\n",
				"\ttools=tools,\n",
				"\tprompt=prompt,\n",
				"\tagent_type=\"tool_calling\",\n",
				"\tagent_verbose=False,\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"res = []\n",
				"async for chunk in agent.astream_events_basic(\n",
				"\t# \"Người phụ trách bộ môn Điều khiển tự động khoa Điện\",\n",
				"\t# \"Các tiến sĩ trong khoa Điện\", # adjust prompt to return all result\n",
				"\t# \"Các thạc sĩ trong khoa Điện\",\n",
				"\t\"Ký túc xá\",\n",
				"  show_tool_call=True,\n",
				"  history_type=\"mongodb\",\n",
				"  user_id=utils.generate_unique_id(thing=\"uuid_name\"),\n",
				"\tsession_id=utils.generate_unique_id(thing=\"uuid\"),\n",
				"):\n",
				"\tprint(chunk, end=\"\", flush=True)\n",
				"\n",
				"\tres.append(chunk)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"result = my_sql_chain.chain_sql.invoke({\n",
				"\t\"question\": \n",
				"   \t\"Các chương trình đào tạo khoa Điện có hình thức liên kết với các trường đại học nước ngoài?\",\n",
				"})\n",
				"\n",
				"result"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "LLM",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.9"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
