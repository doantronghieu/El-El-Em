{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_packages\n",
    "import config\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_langchain import (document_loaders, text_embedding_models, vector_stores,\n",
    "                          text_splitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector stores\n",
    "https://python.langchain.com/docs/integrations/vectorstores/chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = document_loaders.text_loader(\"../../data/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = text_splitters.character_text_splitter(\n",
    "  chunk_size=1000, chunk_overlap=0,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_fn = text_embedding_models.openai_embeddings()\n",
    "\n",
    "chroma_path = \"../../data/store/chroma_db\"\n",
    "db = vector_stores.chroma_store.from_documents(\n",
    "  docs, \n",
    "  embedding_fn,\n",
    "  persist_directory=chroma_path\n",
    ")\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_db = vector_stores.chroma_store(\n",
    "  persist_directory=chroma_path, embedding_function=embedding_fn,\n",
    ")\n",
    "docs = loaded_db.similarity_search(query)\n",
    "pprint(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing a Chroma Client into Langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_or_create_collection(\n",
    "  \"../../data/store/chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Docker Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update and Delete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use OpenAI Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity search with score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering on metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-querying retriever\n",
    "https://python.langchain.com/docs/integrations/retrievers/self_query/chroma_self_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag-chroma\n",
    "https://python.langchain.com/docs/templates/rag-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag-chroma-private\n",
    "https://python.langchain.com/docs/templates/rag-chroma-private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag-chroma-multi-modal\n",
    "https://python.langchain.com/docs/templates/rag-chroma-multi-modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag-chroma-multi-modal-multi-vector\n",
    "https://python.langchain.com/docs/templates/rag-chroma-multi-modal-multi-vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag-multi-modal-local\n",
    "https://python.langchain.com/docs/templates/rag-multi-modal-local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rag-gemini-multi-modal\n",
    "https://python.langchain.com/docs/templates/rag-gemini-multi-modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
