{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import add_packages\n",
    "import config\n",
    "from pprint import pprint\n",
    "\n",
    "from my_langchain import (\n",
    "    document_loaders, text_splitters, text_embedding_models, vector_stores,\n",
    "    chat_models, prompts, utils, output_parsers, agents, documents, runnables,\n",
    "    llms, histories, tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "Build an agent with two tools: one for online searches and one for specific data retrieval from an index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tools needed: Tavily for online search and a retriever for local index.\n",
    "\n",
    "tool_tavily_search = tools.tavily_search_results()\n",
    "\n",
    "# Create a retriever over data. \n",
    "loader = document_loaders.WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "document = loader.load()\n",
    "documents = text_splitters.RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000, chunk_overlap=200,\n",
    ").split_documents(document)\n",
    "\n",
    "embeddings = text_embedding_models.OpenAIEmbeddings()\n",
    "vectorstore = vector_stores.chroma.Chroma.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "tool_retriever = vector_stores.create_retriever_tool(\n",
    "  retriever=retriever,\n",
    "  name=\"langsmith_search\",\n",
    "  description=\"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")\n",
    "\n",
    "# List of tools will use downstream.\n",
    "tools = [\n",
    "  tool_tavily_search, \n",
    "  tool_retriever,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose LLM guiding agent.\n",
    "llm = chat_models.chat_openai\n",
    "\n",
    "# Choose the prompt to guide the agent.\n",
    "prompt = prompts.hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Initialize the agent with the LLM, prompt, and tools. \n",
    "# The agent takes in input and decides on actions. \n",
    "# AgentExecutor execute actions for Agent\n",
    "agent = agents.create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = agents.AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run agent on stateless queries.\n",
    "agent_executor.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in memory\n",
    "\n",
    "This agent is stateless, does not remember previous interactions. To give it memory, pass in previous chat_history. It needs to be called chat_history because of the prompt used. If a different prompt is used, the variable name could be changed.\n",
    "\n",
    "Keep track of messages automatically by wrapping in a RunnableWithMessageHistory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"Hi, I'm Bob\", 'history': [], 'output': 'Hello Bob! How can I assist you today?'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm sorry, but I don't have access to personal information like your name. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is my name?', 'history': [HumanMessage(content=\"Hi, I'm Bob\"), AIMessage(content='Hello Bob! How can I assist you today?')], 'output': \"I'm sorry, but I don't have access to personal information like your name. How can I assist you today?\"}\n"
     ]
    }
   ],
   "source": [
    "# Chat history is stored in memory using a global Python dictionary.\n",
    "store = {}\n",
    "\n",
    "def get_session_history(\n",
    "  user_id: str, conversation_id: str\n",
    ") -> histories.BaseChatMessageHistory:\n",
    "  \"\"\"\n",
    "  Callable references a dict to return an instance of ChatMessageHistory. \n",
    "  \n",
    "  The arguments can be specified by passing a configuration to the \n",
    "  RunnableWithMessageHistory at runtime. \n",
    "  \n",
    "  The configuration parameters for tracking message histories can be customized \n",
    "  by passing a list of ConfigurableFieldSpec objects to the \n",
    "  history_factory_config parameter. \n",
    "  \n",
    "  Two parameters used are user_id and conversation_id.\n",
    "  \"\"\"\n",
    "  if (user_id, conversation_id) not in store:\n",
    "    store[(user_id, conversation_id)] = histories.ChatMessageHistory()\n",
    "  return store[(user_id, conversation_id)]\n",
    "\n",
    "agent_with_memory = runnables.RunnableWithMessageHistory(\n",
    "  agent_executor,\n",
    "  get_session_history,\n",
    "  input_messages_key=\"input\",  # latest input message\n",
    "  history_messages_key=\"history\",  # key to add historical messages to\n",
    "  history_factory_config=[\n",
    "    runnables.ConfigurableFieldSpec(\n",
    "      id=\"user_id\", annotation=str, name=\"User ID\", default=\"\",\n",
    "      description=\"Unique identifier for the user.\", is_shared=True,\n",
    "    ),\n",
    "    runnables.ConfigurableFieldSpec(\n",
    "      id=\"conversation_id\", annotation=str, name=\"Conversation ID\", default=\"\", \n",
    "      description=\"Unique identifier for the conversation.\", is_shared=True,\n",
    "    ),\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(agent_with_memory.invoke(\n",
    "    {\"input\": \"Hi, I'm Bob\"},\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}}\n",
    "))\n",
    "\n",
    "print(agent_with_memory.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}}\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob! How can I assist you today, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob! How can I assist you today, Bob?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = histories.ChatMessageHistory()\n",
    "\n",
    "agent_with_chat_history = runnables.RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")\n",
    "\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Chat Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-ask with search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Agent as an Iterator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning Structured Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle parsing errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access intermediate steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cap the max number of iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeouts for agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolkits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Custom Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools as OpenAI Functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
