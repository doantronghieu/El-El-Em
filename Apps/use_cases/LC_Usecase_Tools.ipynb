{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import add_packages\n",
    "import config\n",
    "from pprint import pprint\n",
    "import os, typing\n",
    "\n",
    "from my_langchain import (\n",
    "  document_loaders, text_splitters, text_embedding_models, vector_stores, \n",
    "  chat_models, prompts, utils, output_parsers, agents, memories, chains,\n",
    "  runnables, agent_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool use (Usecase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart\n",
    "\n",
    "Create Chains and Agents to call Tools, which can be APIs, functions, databases, etc. Tools extend a model's capabilities beyond text/messages. Prompt and parse-output a model correctly to choose the right tools and inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent_tools.tool\n",
    "def tool_multiply(a: int, b: int) -> int:\n",
    "  \"\"\"Multiply two integers together.\"\"\"\n",
    "  return a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chains\n",
    "\n",
    "Create a chain for using a tool a fixed number of times, like a simple chain that multiplies user-specified numbers.\n",
    "\n",
    "\n",
    "Using function calling APIs with LLM models that support it like OpenAI models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and tools. \n",
    "model = chat_models.chat_openai\n",
    "\n",
    "# Convert LangChain Tool to OpenAI JSONSchema function, bind as tools argument \n",
    "# for ChatOpenAI calls. Specify tool_choice for single Tool in initial chain to\n",
    "# ensure consistent use. \n",
    "model_tools_equipped = model.bind_tools([tool_multiply], tool_choice=\"tool_multiply\")\n",
    "\n",
    "# Compose tool-calling model using JsonOutputToolsParser to convert OpenAI \n",
    "# function-calling response to list of {\"type\": \"TOOL_NAME\", \"args\": {...}} \n",
    "# dicts with tools and arguments.\n",
    "chain = (\n",
    "  model_tools_equipped \n",
    "  | output_parsers.JsonOutputToolsParser(key_name=\"tool_multiply\", return_single=True)\n",
    "  | tool_multiply\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents\n",
    "\n",
    "Chains are useful for specific tool sequences. In some cases, tool usage depends on input. Agents allow the model to determine tool usage frequency and order.\n",
    "\n",
    "LangChain has built-in agents optimized for various use cases. \n",
    "\n",
    "OpenAI tools agent utilizes the new OpenAI tool-calling API. This differs from function-calling as the model can return multiple function invocations at once.\n",
    "\n",
    "Agents can to use multiple tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompts.hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "@agent_tools.tool\n",
    "def tool_add(a: int, b: int) -> int:\n",
    "  \"\"\"Add two integers.\"\"\"\n",
    "  return a + b\n",
    "\n",
    "@agent_tools.tool\n",
    "def tool_exponentiate(base: int, exponent: int) -> int:\n",
    "  \"\"\"Exponentiate the base to the exponent power.\"\"\"\n",
    "  return base**exponent\n",
    "\n",
    "tools = [\n",
    "  tool_add,\n",
    "  tool_exponentiate,\n",
    "  tool_multiply,\n",
    "]\n",
    "\n",
    "model = chat_models.chat_openai\n",
    "agent = agents.create_openai_tools_agent(model, tools, prompt)\n",
    "agent_executor = agents.AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_exponentiate` with `{'base': 3, 'exponent': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_add` with `{'a': 12, 'b': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_multiply` with `{'a': 243, 'b': 15}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m3645\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_exponentiate` with `{'base': 3645, 'exponent': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m13286025\u001b[0m\u001b[32;1m\u001b[1;3mThe result of taking 3 to the fifth power and multiplying that by the sum of twelve and three, then squaring the whole result is 13,286,025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "  (\"Take 3 to the fifth power and multiply that by the sum of twelve and three, \"\n",
    "   \"then square the whole result\"),\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "  agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "Chains are useful for specific tool sequences. In some cases, tool usage depends on input. Agents allow the model to determine tool usage frequency and order.\n",
    "\n",
    "LangChain has various built-in agents optimized for different use cases.\n",
    "\n",
    "OpenAI tools agent utilizes OpenAI tool-calling API differs from function-calling as the model can return multiple function invocations at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* TOOLS\n",
    "\n",
    "@agent_tools.tool\n",
    "def tool_add(a: int, b: int) -> int:\n",
    "  \"\"\"Add two integers.\"\"\"\n",
    "  return a + b\n",
    "\n",
    "@agent_tools.tool\n",
    "def tool_exponentiate(base: int, exponent: int) -> int:\n",
    "  \"\"\"Exponentiate the base to the exponent power.\"\"\"\n",
    "  return base**exponent\n",
    "\n",
    "@agent_tools.tool\n",
    "def tool_multiply(a: int, b: int) -> int:\n",
    "  \"\"\"Multiply two integers together.\"\"\"\n",
    "  return a*b\n",
    "\n",
    "tools = [\n",
    "  tool_add,\n",
    "  tool_exponentiate,\n",
    "  tool_multiply,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#* PROMPT\n",
    "prompt = prompts.hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* AGENT\n",
    "model = chat_models.chat_openai\n",
    "agent = agents.create_openai_tools_agent(llm=model, tools=tools, prompt=prompt)\n",
    "agent_executor = agents.AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_exponentiate` with `{'base': 3, 'exponent': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_add` with `{'a': 12, 'b': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_multiply` with `{'a': 243, 'b': 15}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m3645\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tool_exponentiate` with `{'base': 3645, 'exponent': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m13286025\u001b[0m\u001b[32;1m\u001b[1;3mThe result of taking 3 to the fifth power and multiplying that by the sum of twelve and three, then squaring the whole result is 13,286,025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "  (\"Take 3 to the fifth power and multiply that by the sum of twelve and three, \"\n",
    "   \"then square the whole result\"),\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "  agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool use without function calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-in-the-loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel tool use\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
