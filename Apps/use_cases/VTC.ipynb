{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import add_packages\n",
    "import config\n",
    "from pprint import pprint\n",
    "import os, re, unicodedata, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from my_langchain import (\n",
    "  document_loaders, text_splitters, text_embedding_models, vector_stores, \n",
    "  chat_models, prompts, utils, output_parsers, agents, documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectures Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_course_name(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        first_line = file.readline().strip()\n",
    "        return first_line[len(\"# Course: \"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_newlines(text):\n",
    "    while '\\n\\n' in text:\n",
    "        text = text.replace('\\n\\n', '\\n')\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_double_spaces(text):\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ', ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_add_space_after_hash(text):\n",
    "    pattern = r'##(\\w)'\n",
    "    processed_text = re.sub(pattern, r'## \\1', text)\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def process_remove_quotes(text):\n",
    "    cleaned_text = text.replace('\"', '')\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def process_text_file(input_file, output_file, functions):\n",
    "    # Read the first line of the input file\n",
    "    with open(input_file, 'r') as file:\n",
    "        first_line = file.readline().strip()\n",
    "        len_first_line = len(first_line)\n",
    "    \n",
    "\n",
    "    # Extract course name from filename\n",
    "    course_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    # If the first line doesn't match the filename, replace it with the filename's course name\n",
    "    first_line = \"# Course: \" + course_name\n",
    "\n",
    "    # Reopen the file to process the entire content\n",
    "    with open(input_file, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Apply processing functions\n",
    "    for func in functions:\n",
    "        text = func(text)\n",
    "\n",
    "    # Prepend the modified first line to the processed text\n",
    "    text = first_line + '\\n' + text[len_first_line + 1:]\n",
    "\n",
    "    # Write the processed text to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "\n",
    "# Define the list of functions to apply\n",
    "functions_to_apply = [\n",
    "    process_remove_quotes,\n",
    "    remove_extra_newlines,\n",
    "    remove_double_spaces,\n",
    "    process_add_space_after_hash,\n",
    "]\n",
    "\n",
    "# Example usage:\n",
    "input_file_path = '../data/vtc1/script/KỸ NĂNG TÌM VIỆC LÀM THÊM.txt'\n",
    "output_file_path = '../data/vtc1/script/KỸ NĂNG TÌM VIỆC LÀM THÊM.txt'\n",
    "process_text_file(input_file_path, output_file_path, functions_to_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the files\n",
    "folder_path = '../data/vtc1/script/'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):  # Process only text files\n",
    "        input_file_path = os.path.join(folder_path, filename)\n",
    "        output_file_path = os.path.join(\n",
    "            folder_path, filename)  # Output file path\n",
    "        process_text_file(input_file_path, output_file_path,\n",
    "                          functions_to_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documents of one course\n",
    "# Example usage:\n",
    "file_path = \"../data/vtc1/script/HỘI HỌA - MÀU SẮC VÀ PHỐI MÀU CƠ BẢN.txt\"\n",
    "course_name = extract_course_name(file_path).lower()\n",
    "\n",
    "text_loader_lectures_content = document_loaders.TextLoader(file_path)\n",
    "document = text_loader_lectures_content.load()\n",
    "\n",
    "text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000, chunk_overlap=200,\n",
    ")\n",
    "docs_lectures_content = text_splitter.split_documents(document)\n",
    "\n",
    "metadatas = {\n",
    "  \"data\": \"lectures content\",\n",
    "  \"course_name\": course_name,\n",
    "}\n",
    "utils.remove_metadata(docs_lectures_content, \"source\")\n",
    "utils.update_metadata(docs_lectures_content, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    data_dict = {}\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                course_name = extract_course_name(file_path).lower()\n",
    "\n",
    "                text_loader_lectures_content = document_loaders.TextLoader(file_path)\n",
    "                document = text_loader_lectures_content.load()\n",
    "\n",
    "                text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=1000, chunk_overlap=200,\n",
    "                )\n",
    "                docs_lectures_content = text_splitter.split_documents(document)\n",
    "\n",
    "                metadatas = {\n",
    "                    \"data\": \"lectures content\",\n",
    "                    \"course_name\": course_name,\n",
    "                }\n",
    "                utils.remove_metadata(docs_lectures_content, \"source\")\n",
    "                utils.update_metadata(docs_lectures_content, metadatas)\n",
    "\n",
    "                data_dict[course_name] = docs_lectures_content\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "folder_path = \"../data/vtc1/script/\"\n",
    "docs_lectures_content_dict = process_folder(folder_path)\n",
    "for file_name, content in docs_lectures_content_dict.items():\n",
    "    print(f\"File: {file_name}, Course: {content[0].metadata['course_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_loader_faq = document_loaders.TextLoader(\n",
    "  \"../data/vtc/faq.txt\"\n",
    ")\n",
    "document = text_loader_faq.load()\n",
    "\n",
    "text_splitter = text_splitters.RecursiveCharacterTextSplitter(\n",
    "  chunk_size=500, chunk_overlap=100,\n",
    ")\n",
    "docs_faq = text_splitter.split_documents(document)\n",
    "\n",
    "metadatas = {\n",
    "  \"data\": \"frequently asked questions\"\n",
    "}\n",
    "utils.remove_metadata(docs_faq, \"source\")\n",
    "utils.update_metadata(docs_faq, metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courses list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_list_cols = utils.get_csv_column_names(\"../data/vtc1/courses_list.csv\")\n",
    "\n",
    "csv_loader_courses_list = document_loaders.CSVLoader(\n",
    "  \"../data/vtc1/courses_list.csv\",\n",
    "  # source_column=\"No\",\n",
    "  csv_args={\n",
    "      \"delimiter\": \",\",\n",
    "      # \"quotechar\": \"''\",\n",
    "      \"fieldnames\": courses_list_cols,\n",
    "  },\n",
    ")\n",
    "document = csv_loader_courses_list.load()[1:]\n",
    "docs_courses_information = document\n",
    "\n",
    "metadatas = {\n",
    "  \"data\": \"courses information\"\n",
    "}\n",
    "utils.remove_metadata(docs_courses_information, \"source\")\n",
    "utils.remove_metadata(docs_courses_information, \"row\")\n",
    "utils.update_metadata(docs_courses_information, metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_instance_lectures_content = vector_stores.QdrantWrapper(\n",
    "  collection_name=\"vtc-lectures-content-new\",\n",
    "  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
    "  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
    "  default_search_type=\"similarity\",\n",
    "  default_search_kwargs={\"k\": 5},\n",
    "  retriever_tool_name=\"lectures_content\",\n",
    "  retriever_tool_description=\"Searches and returns content, knowledge from \\\n",
    "    the lecture scripts based on specialized keywords from user's question like \\\n",
    "    Typography, Lazada, Premiere, Unity ...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add multiple courses\n",
    "# for docs in docs_lectures_content_dict.values():\n",
    "#   qdrant_instance_lectures_content.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one course\n",
    "# qdrant_instance_lectures_content.add_documents(docs_lectures_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_instance_faq = vector_stores.QdrantWrapper(\n",
    "  collection_name=\"vtc-faq\",\n",
    "  qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
    "  qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
    "  default_search_type=\"similarity\",\n",
    "  default_search_kwargs={\"k\": 10},\n",
    "  retriever_tool_name=\"frequently_asked_questions\",\n",
    "  retriever_tool_description=\"Searches and returns answer for frequently asked \\\n",
    "    questions about Onlinica information like accounts, fees, courses, payments, \\\n",
    "    certificates ...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdrant_instance_faq.add_documents(docs_faq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_instance_courses_information = vector_stores.QdrantWrapper(\n",
    "    collection_name=\"vtc-courses-information-new\",\n",
    "    qdrant_host=os.getenv(\"QDRANT_HOST\"),\n",
    "    qdrant_api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
    "    default_search_type=\"similarity\",\n",
    "    default_search_kwargs={\"k\": 10},\n",
    "    retriever_tool_name=\"courses_information\",\n",
    "    retriever_tool_description=\"Searches and returns information about courses \\\n",
    "      of Onlinica like course name, course category, course link, course \\\n",
    "      description, total number of courses ...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdrant_instance_courses_information.add_documents(docs_courses_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bạn là một nhân viên tư vấn của một nền tảng học tập trực tuyến tên là Onlinica.\n",
    "\n",
    "Bạn có các phẩm chất sau: \n",
    "- Hay giúp đỡ\n",
    "- Cực kỳ tận tâm và chăm chỉ\n",
    "- Tư cách chuyên nghiệp, tôn trọng, chân thành và trung thực\n",
    "- Tư duy chuẩn mực\n",
    "- Kỹ năng giao tiếp, đàm phán, xử lý phàn nàn xuất sắc\n",
    "- Kỹ năng bán hàng xuất sắc\n",
    "- Hiểu biết sâu sắc về sản phẩm/dịch vụ. Kiến thức vững về ngành nghề\n",
    "- Tinh thần lạc quan và tích cực. Khả năng tạo ra trải nghiệm tích cực cho khách hàng\n",
    "- Nhạy bén với yêu cầu và mong muốn của khách hàng\n",
    "\n",
    "Bạn sẽ giúp người dùng trả lời các câu hỏi về các khóa học trên nền tảng. Ngôn ngữ mà bạn trả lời sẽ giống với ngôn ngữ của người dùng.\n",
    "\n",
    "Các câu hỏi mà người dùng có thể hỏi và cách trả lời:\n",
    "- Thông tin cơ bản về khóa học: Bạn NÊN liệt kê TẤT CẢ các khóa học hiện có (và thông tin của chúng) LIÊN QUAN đến câu hỏi của người dùng.\n",
    "- Nội dung, kiến thức của bài giảng: Các câu hỏi này thường sẽ chứa các từ khóa chuyên ngành như Typography, Lazada, Premiere, Unity,... Bạn sẽ tổng hợp thông tin từ script của các bài giảng có chứa từ khóa chuyên ngành đó và đưa ra câu trả lời chi tiết cho người dùng. Bạn nên gợi ý các khóa học (tên khóa học kèm link khóa học) có liên quan đến từ khóa chuyên ngành đó cho người dùng.\n",
    "- Các câu hỏi thường được hỏi\n",
    "\"\"\"\n",
    "\n",
    "onlinica_system_message = \"\"\"\\\n",
    "You are a consultant for an online learning platform called Onlinica.\n",
    "\n",
    "You have the following qualities:\n",
    "- Helpful\n",
    "- Extremely dedicated and hardworking\n",
    "- Professionalism, respect, sincerity and honesty\n",
    "- Standard thinking\n",
    "- Excellent communication, negotiation and complaint handling skills\n",
    "- Excellent sales skills\n",
    "- Deep understanding of products/services. Strong knowledge of the industry\n",
    "- Optimistic and positive spirit. Ability to create a positive customer experience\n",
    "- Sensitive to customers' requests and desires\n",
    "\n",
    "You will help users answer questions about the courses on the platform. The language in which you respond will be the same as the user's language.\n",
    "\n",
    "Questions users might ask and how to answer:\n",
    "- Course basics: You SHOULD list ALL available courses (and their information) that are RELEVANT to the user's question.\n",
    "- Content and knowledge of the lecture: These questions will often contain specialized keywords such as Typography, Lazada, Premiere, Unity,... You will synthesize information from the scripts of the lectures that contain keywords that major and give detailed answers to users. You should suggest courses (course name with course link) related to that specialized keyword to users.\n",
    "- Frequently asked questions\\\n",
    "\"\"\"\n",
    "onlinica_prompt = prompts.create_openai_tools_agent_custom_prompt(onlinica_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  qdrant_instance_lectures_content.retriever_tool,\n",
    "  qdrant_instance_faq.retriever_tool,\n",
    "  qdrant_instance_courses_information.retriever_tool,\n",
    "]\n",
    "\n",
    "llm = chat_models.chat_openai\n",
    "agent = agents.MyAgent(prompt=onlinica_prompt, tools=tools, agent_type=\"openai_tools\", llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "  \"xin chào. Tên tôi là Bob.\",\n",
    "  \"bạn có nhớ tên tôi là gì không\",\n",
    "  \n",
    "  \"digital marketing là gì\",\n",
    "  \n",
    "  \"làm cách nào để đăng ký tài khoản onlinica\",\n",
    "  \"có mấy loại tài khoản onlinica\",\n",
    "  \"các khoá học tại onlinica có thời hạn sử dụng bao lâu\",\n",
    "  \"onlinica có mấy hình thức thanh toán\",\n",
    "  \"có thể thanh toán bằng momo được không\",\n",
    "  \n",
    "  \"các khóa học về design\",\n",
    "  \"các khóa học về trí tuệ nhân tạo\",\n",
    "  \"các khóa học về  ai\",\n",
    "  \"các khóa học của nguyễn ngọc tú uyên\",\n",
    "  \"các khóa học của tú uyên\",\n",
    "  \"các khóa học thầy trần anh tuấn dạy\",\n",
    "  \n",
    "  \"cách quản lý thời gian\",\n",
    "  \"nguyên lý phối màu\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke_agent(\n",
    "    \"có thể thanh toán bằng momo được không\"\n",
    ")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
