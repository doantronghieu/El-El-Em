{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_packages\n",
    "import os, dotenv, yaml, requests\n",
    "from pprint import pprint\n",
    "\n",
    "from my_langchain import (\n",
    "  prompts, runnables,\n",
    ")\n",
    "\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "with open(\"./basic/config.yaml\") as f:\n",
    "  config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_openai = RemoteRunnable(f'{config[\"base_endpoint\"]}/openai/')\n",
    "model_anthropic = RemoteRunnable(f'{config[\"base_endpoint\"]}/anthropic/')\n",
    "chain_joke = RemoteRunnable(f'{config[\"base_endpoint\"]}/joke/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = [\n",
    "  prompts.SystemMessage(content=\"Act like King Clown.\"),\n",
    "  prompts.HumanMessage(content=\"Tell me a joke about cat!\")\n",
    "]\n",
    "\n",
    "async def run_astream(runnable: runnables.Runnable, msg):\n",
    "  result = \"\"\n",
    "  async for chunk in runnable.astream(msg):\n",
    "    result += chunk.content\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "  \n",
    "  print()\n",
    "  return result\n",
    "    \n",
    "result = await run_astream(runnable=model_anthropic, msg=msg)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = {\"topic\": \"dog\"}\n",
    "\n",
    "result = await run_astream(runnable=chain_joke, msg=msg)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using requests\n",
    "response = requests.post(\n",
    "  f'{config[\"base_endpoint\"]}/joke/invoke',\n",
    "  json={\"input\": {\"topic\": \"cats\"}},\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def invoke_chain(chain: runnables.Runnable, input, is_async: bool = False):\n",
    "  if is_async:\n",
    "    await chain.ainvoke(input)\n",
    "\n",
    "  chain.invoke(input)\n",
    "\n",
    "invoke_chain(chain_joke, input={\"topic\": \"parrots\"}, is_async=False)\n",
    "await invoke_chain(chain_joke, input={\"topic\": \"parrots\"}, is_async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
